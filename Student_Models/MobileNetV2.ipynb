{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8afdcbde",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import cv2\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "import random\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59a331",
   "metadata": {},
   "source": [
    "## visualisation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set publication-quality style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 100  # Lower for notebook display, saved figures will be 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "class TrainingLogger:\n",
    "    \"\"\"Logger to track training metrics epoch-by-epoch\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'train_acc_species': [],\n",
    "            'val_acc_species': [],\n",
    "            'train_acc_health': [],\n",
    "            'val_acc_health': [],\n",
    "            'lr': []\n",
    "        }\n",
    "    \n",
    "    def log_epoch(self, epoch, train_stats, val_stats, lr):\n",
    "        \"\"\"Log metrics for one epoch\"\"\"\n",
    "        self.history['epoch'].append(epoch)\n",
    "        self.history['train_loss'].append(train_stats['loss'])\n",
    "        self.history['val_loss'].append(val_stats['loss'])\n",
    "        self.history['train_acc_species'].append(train_stats['acc_species'])\n",
    "        self.history['val_acc_species'].append(val_stats['acc_species'])\n",
    "        self.history['train_acc_health'].append(train_stats['acc_health'])\n",
    "        self.history['val_acc_health'].append(val_stats['acc_health'])\n",
    "        self.history['lr'].append(lr)\n",
    "    \n",
    "    def plot_convergence(self, save_path='training_convergence.png', model_name='Model', show=True):\n",
    "        \"\"\"\n",
    "        Create publication-quality convergence plots\n",
    "        \n",
    "        Args:\n",
    "            save_path: Path to save the figure\n",
    "            model_name: Name of the model for the title\n",
    "            show: Whether to display the plot in notebook (default: True)\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(f'{model_name} Training Convergence', fontsize=14, fontweight='bold', y=0.995)\n",
    "        \n",
    "        epochs = self.history['epoch']\n",
    "        \n",
    "        # Plot 1: Training and Validation Loss\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(epochs, self.history['train_loss'], 'o-', label='Train Loss', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax1.plot(epochs, self.history['val_loss'], 's-', label='Val Loss', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('(a) Multi-task Loss', fontweight='bold', loc='left')\n",
    "        ax1.legend(framealpha=0.9)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Species Accuracy\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(epochs, self.history['train_acc_species'], 'o-', label='Train Species', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax2.plot(epochs, self.history['val_acc_species'], 's-', label='Val Species', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('(b) Species Classification', fontweight='bold', loc='left')\n",
    "        ax2.set_ylim([0, 1.05])\n",
    "        ax2.legend(framealpha=0.9)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Disease Accuracy\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(epochs, self.history['train_acc_health'], 'o-', label='Train Disease', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax3.plot(epochs, self.history['val_acc_health'], 's-', label='Val Disease', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('Accuracy')\n",
    "        ax3.set_title('(c) Disease Detection', fontweight='bold', loc='left')\n",
    "        ax3.set_ylim([0, 1.05])\n",
    "        ax3.legend(framealpha=0.9)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Learning Rate (replacing joint accuracy)\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(epochs, self.history['lr'], 'o-', label='Learning Rate', \n",
    "                linewidth=2, markersize=4, color='#F18F01', alpha=0.8)\n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Learning Rate')\n",
    "        ax4.set_title('(d) Learning Rate Schedule', fontweight='bold', loc='left')\n",
    "        ax4.legend(framealpha=0.9)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Convergence plot saved to: {save_path}\")\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def plot_learning_rate(self, save_path='learning_rate_schedule.png', show=True):\n",
    "        \"\"\"Plot learning rate schedule\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        \n",
    "        epochs = self.history['epoch']\n",
    "        ax.plot(epochs, self.history['lr'], 'o-', linewidth=2, \n",
    "               markersize=5, color='#F18F01', label='Learning Rate')\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate')\n",
    "        ax.set_title('Learning Rate Schedule (Cosine Annealing)', fontweight='bold')\n",
    "        ax.legend(framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Learning rate plot saved to: {save_path}\")\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def plot_comparison(self, other_loggers, labels, save_path='model_comparison.png', show=True):\n",
    "        \"\"\"\n",
    "        Compare multiple models on the same plot\n",
    "        \n",
    "        Args:\n",
    "            other_loggers: List of other TrainingLogger instances\n",
    "            labels: List of model names\n",
    "            save_path: Path to save comparison figure\n",
    "            show: Whether to display the plot in notebook\n",
    "        \"\"\"\n",
    "        all_loggers = [self] + other_loggers\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "        fig.suptitle('Multi-Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', '#BC4B51', '#8B5A3C']\n",
    "        \n",
    "        # Plot 1: Validation Loss Comparison\n",
    "        ax1 = axes[0]\n",
    "        for i, (logger, label) in enumerate(zip(all_loggers, labels)):\n",
    "            ax1.plot(logger.history['epoch'], logger.history['val_loss'], \n",
    "                    'o-', label=label, linewidth=2, markersize=4, \n",
    "                    color=colors[i % len(colors)], alpha=0.8)\n",
    "        \n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Validation Loss')\n",
    "        ax1.set_title('(a) Validation Loss', fontweight='bold', loc='left')\n",
    "        ax1.legend(framealpha=0.9, loc='best')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Health Accuracy Comparison\n",
    "        ax2 = axes[1]\n",
    "        for i, (logger, label) in enumerate(zip(all_loggers, labels)):\n",
    "            ax2.plot(logger.history['epoch'], logger.history['val_acc_health'], \n",
    "                    'o-', label=label, linewidth=2, markersize=4, \n",
    "                    color=colors[i % len(colors)], alpha=0.8)\n",
    "        \n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Validation Health Accuracy')\n",
    "        ax2.set_title('(b) Health Accuracy', fontweight='bold', loc='left')\n",
    "        ax2.set_ylim([0, 1.05])\n",
    "        ax2.legend(framealpha=0.9, loc='best')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Comparison plot saved to: {save_path}\")\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def save_history(self, save_path='training_history.csv'):\n",
    "        \"\"\"Save training history to CSV\"\"\"\n",
    "        df = pd.DataFrame(self.history)\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"✓ Training history saved to: {save_path}\")\n",
    "\n",
    "print(\"✓ TrainingLogger class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1daa57",
   "metadata": {},
   "source": [
    "## training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================================\n",
    "# HYPERPARAMETERS & CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "# --- PATHS ---\n",
    "DATA_ROOT = Path(\"/Users/alimran/Desktop/CSE465/Split_Dataset\")  # Updated path\n",
    "\n",
    "# --- MODEL CONFIG ---\n",
    "MODEL_NAME = \"MobileNetV2\"\n",
    "IMG_SIZE = 224  # Input image size (MobileNetV2 uses 224)\n",
    "NUM_SPECIES = 3  # Eggplant, Potato, Tomato\n",
    "NUM_HEALTH = 4   # Bacterial, Fungal, Healthy, Virus\n",
    "DROPOUT = 0.3    # Dropout rate\n",
    "PRETRAINED = False  # ✅ Use ImageNet pretrained weights (recommended)\n",
    "\n",
    "# --- TRAINING CONFIG ---\n",
    "BATCH_SIZE = 32         # ✅ Increased from 16 for better gradient stability\n",
    "NUM_WORKERS = 0         # Set to 0 to avoid multiprocessing issues (increase to 4-8 if stable)\n",
    "EPOCHS = 50             # Maximum training epochs\n",
    "PATIENCE = 5            # Early stopping patience\n",
    "SEED = 42               # Random seed for reproducibility\n",
    "\n",
    "# --- OPTIMIZER CONFIG ---\n",
    "LR = 1e-4               # ✅ Increased from 1e-4 (better for pretrained + batch 32)\n",
    "WEIGHT_DECAY = 5e-4     # L2 regularization\n",
    "BETAS = (0.9, 0.999)    # Adam beta parameters\n",
    "\n",
    "# --- LOSS CONFIG ---\n",
    "LOSS_WEIGHT_HEALTH = 1.0  # Weight for health classification loss (1.0 = equal weight)\n",
    "\n",
    "# --- TRAINING OPTIMIZATIONS ---\n",
    "USE_AMP = True          # Automatic Mixed Precision (faster training)\n",
    "GRADIENT_CLIP = 1.0     # Gradient clipping value (None to disable)\n",
    "\n",
    "# --- DEVICE SETUP ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "                      else \"cpu\")\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\"*70)\n",
    "print(f\"{'MODEL CONFIGURATION':^70}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model:              {MODEL_NAME}\")\n",
    "print(f\"Pretrained:         {PRETRAINED}\")\n",
    "print(f\"Image Size:         {IMG_SIZE}×{IMG_SIZE}\")\n",
    "print(f\"Device:             {device}\")\n",
    "print(f\"\\n{'TRAINING CONFIGURATION':^70}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Batch Size:         {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate:      {LR}\")\n",
    "print(f\"Weight Decay:       {WEIGHT_DECAY}\")\n",
    "print(f\"Dropout:            {DROPOUT}\")\n",
    "print(f\"Epochs:             {EPOCHS} (patience={PATIENCE})\")\n",
    "print(f\"Mixed Precision:    {USE_AMP}\")\n",
    "print(f\"Gradient Clipping:  {GRADIENT_CLIP if GRADIENT_CLIP else 'Disabled'}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED} for reproducibility\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Label maps (case-insensitive)\n",
    "# -------------------------------\n",
    "SPECIES_MAP = {\"eggplant\": 0, \"potato\": 1, \"tomato\": 2}\n",
    "HEALTH_MAP = {\"bacterial\": 0, \"fungal\": 1, \"healthy\": 2, \"virus\": 3}\n",
    "\n",
    "print(\"Label Mappings:\")\n",
    "print(f\"  Species: {SPECIES_MAP}\")\n",
    "print(f\"  Health:  {HEALTH_MAP}\\n\")\n",
    "\n",
    "def parse_joint_label(folder_name: str) -> Tuple[int,int]:\n",
    "    name = folder_name.strip()\n",
    "    if \"_\" not in name:\n",
    "        raise ValueError(f\"Folder name not joint label: {name}\")\n",
    "    sp, he = name.split(\"_\", 1)\n",
    "    sp_id = SPECIES_MAP[sp.lower()]\n",
    "    he_id = HEALTH_MAP[he.lower()]\n",
    "    return sp_id, he_id\n",
    "\n",
    "# -------------------------------\n",
    "# Dataset\n",
    "# -------------------------------\n",
    "class JointLeafDataset(Dataset):\n",
    "    def __init__(self, split_root: Path, transform=None):\n",
    "        self.split_root = Path(split_root)\n",
    "        self.samples: List[Tuple[str, int, int]] = []\n",
    "        self.transform = transform\n",
    "        for folder in sorted([d for d in self.split_root.iterdir() if d.is_dir()]):\n",
    "            sp_id, he_id = parse_joint_label(folder.name)\n",
    "            for p in folder.rglob(\"*\"):\n",
    "                if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}:\n",
    "                    self.samples.append((str(p), sp_id, he_id))\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(f\"No images found under {split_root}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, sp_id, he_id = self.samples[idx]\n",
    "       \n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path}: {e}\")\n",
    "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
    "       \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "       \n",
    "        return img, torch.tensor(sp_id, dtype=torch.long), torch.tensor(he_id, dtype=torch.long)\n",
    "\n",
    "# -------------------------------\n",
    "# Transforms (Compatible with preprocessed dataset)\n",
    "# -------------------------------\n",
    "# NOTE: Augmentation already done offline in Augmentation3.0.ipynb\n",
    "# Here we only apply ImageNet normalization for pretrained model\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
    "])\n",
    "\n",
    "print(\"✓ Transforms configured:\")\n",
    "print(\"  - Train: Resize → ToTensor → ImageNet Normalization\")\n",
    "print(\"  - Val/Test: Resize → ToTensor → ImageNet Normalization\")\n",
    "print(\"  - Note: Offline augmentation already applied in preprocessing\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Datasets & Loaders\n",
    "# -------------------------------\n",
    "print(\"=\"*70)\n",
    "print(\"Loading datasets...\")\n",
    "train_ds = JointLeafDataset(DATA_ROOT / \"train\", transform=train_tf)\n",
    "val_ds   = JointLeafDataset(DATA_ROOT / \"val\",   transform=eval_tf)\n",
    "test_ds  = JointLeafDataset(DATA_ROOT / \"test\",  transform=eval_tf)\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")\n",
    "\n",
    "# Test loading one sample\n",
    "print(\"\\nTesting sample loading...\")\n",
    "try:\n",
    "    sample_img, sample_sp, sample_he = train_ds[0]\n",
    "    print(f\"✓ Sample loaded successfully: shape={sample_img.shape}, species={sample_sp}, health={sample_he}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to load sample: {e}\")\n",
    "    raise\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "# Test DataLoader\n",
    "print(\"\\nTesting DataLoader...\")\n",
    "try:\n",
    "    for i, (imgs, sp, he) in enumerate(train_loader):\n",
    "        print(f\"✓ Batch {i}: imgs {imgs.shape}, species {sp.shape}, health {he.shape}\")\n",
    "        if i >= 2:\n",
    "            break\n",
    "    print(\"✓ DataLoader test passed!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ DataLoader failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af90ba",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskMobileNetV2(nn.Module):\n",
    "    def __init__(self, num_species=NUM_SPECIES, num_health=NUM_HEALTH, pretrained=PRETRAINED, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            weights = MobileNet_V2_Weights.IMAGENET1K_V1\n",
    "            self.backbone = mobilenet_v2(weights=weights)\n",
    "        else:\n",
    "            self.backbone = mobilenet_v2(weights=None)\n",
    "        \n",
    "        # MobileNetV2 has classifier as a Sequential with dropout and linear layer\n",
    "        in_dim = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head_species = nn.Linear(in_dim, num_species)\n",
    "        self.head_health = nn.Linear(in_dim, num_health)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.dropout(feats)\n",
    "        logits_species = self.head_species(feats)\n",
    "        logits_health = self.head_health(feats)\n",
    "        return logits_species, logits_health\n",
    "\n",
    "print(\"Initializing model...\")\n",
    "model = MultiTaskMobileNetV2(num_species=NUM_SPECIES, num_health=NUM_HEALTH, pretrained=PRETRAINED, dropout=DROPOUT).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"✓ Model loaded successfully\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Optimizer / Scheduler / Losses\n",
    "# -------------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "criterion_species = nn.CrossEntropyLoss()\n",
    "criterion_health  = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP and device.type==\"cuda\")\n",
    "\n",
    "# -------------------------------\n",
    "# Utilities\n",
    "# -------------------------------\n",
    "def accuracy(logits, targets):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, model, optimizer=None, train=True, epoch=0):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    running = {\n",
    "        \"loss\": 0.0,\n",
    "        \"acc_species\": 0.0,\n",
    "        \"acc_health\":  0.0,\n",
    "        \"n\": 0\n",
    "    }\n",
    "    total_batches = len(loader)\n",
    "   \n",
    "    for batch_idx, (imgs, y_species, y_health) in enumerate(loader):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        y_species = y_species.to(device, non_blocking=True)\n",
    "        y_health  = y_health.to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.set_grad_enabled(train):\n",
    "            if USE_AMP and device.type==\"cuda\":\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    logits_species, logits_health = model(imgs)\n",
    "                    loss = criterion_species(logits_species, y_species) + \\\n",
    "                           LOSS_WEIGHT_HEALTH * criterion_health(logits_health, y_health)\n",
    "            else:\n",
    "                logits_species, logits_health = model(imgs)\n",
    "                loss = criterion_species(logits_species, y_species) + \\\n",
    "                       LOSS_WEIGHT_HEALTH * criterion_health(logits_health, y_health)\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if USE_AMP and device.type==\"cuda\":\n",
    "                scaler.scale(loss).backward()\n",
    "                if GRADIENT_CLIP:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if GRADIENT_CLIP:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "                optimizer.step()\n",
    "        \n",
    "        acc_sp = accuracy(logits_species, y_species)\n",
    "        acc_he = accuracy(logits_health, y_health)\n",
    "        preds_sp = logits_species.argmax(1)\n",
    "        \n",
    "        bs = imgs.size(0)\n",
    "        running[\"loss\"] += loss.item() * bs\n",
    "        running[\"acc_species\"] += acc_sp * bs\n",
    "        running[\"acc_health\"]  += acc_he * bs\n",
    "        running[\"n\"] += bs\n",
    "        \n",
    "        if (batch_idx + 1) % max(1, total_batches // 10) == 0 or (batch_idx + 1) == total_batches:\n",
    "            avg_loss = running[\"loss\"] / running[\"n\"]\n",
    "            avg_sp = running[\"acc_species\"] / running[\"n\"]\n",
    "            avg_he = running[\"acc_health\"] / running[\"n\"]\n",
    "            print(f\"  [{batch_idx + 1}/{total_batches}] loss: {avg_loss:.4f}, sp: {avg_sp:.3f}, he: {avg_he:.3f}\")\n",
    "    \n",
    "    for k in [\"loss\", \"acc_species\", \"acc_health\"]:\n",
    "        running[k] /= max(1, running[\"n\"])\n",
    "    return running\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17f0ea",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea704e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Training Loop\n",
    "# -------------------------------\n",
    "\n",
    "# Storage for history\n",
    "history = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc_species\": [], \"val_acc_species\": [],\n",
    "    \"train_acc_health\": [], \"val_acc_health\": []\n",
    "}\n",
    "\n",
    "best_val_health = 0.0\n",
    "best_epoch = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    print(\"Training...\")\n",
    "    train_stats = run_epoch(train_loader, model, optimizer, train=True, epoch=epoch)\n",
    "    \n",
    "    # Validate\n",
    "    print(\"Validating...\")\n",
    "    val_stats = run_epoch(val_loader, model, optimizer=None, train=False, epoch=epoch)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Store history\n",
    "    history[\"train_loss\"].append(train_stats[\"loss\"])\n",
    "    history[\"val_loss\"].append(val_stats[\"loss\"])\n",
    "    history[\"train_acc_species\"].append(train_stats[\"acc_species\"])\n",
    "    history[\"val_acc_species\"].append(val_stats[\"acc_species\"])\n",
    "    history[\"train_acc_health\"].append(train_stats[\"acc_health\"])\n",
    "    history[\"val_acc_health\"].append(val_stats[\"acc_health\"])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'EPOCH SUMMARY':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Train - Loss: {train_stats['loss']:.4f} | Species: {train_stats['acc_species']:.3f} | \"\n",
    "          f\"Health: {train_stats['acc_health']:.3f}\")\n",
    "    print(f\"  Val   - Loss: {val_stats['loss']:.4f} | Species: {val_stats['acc_species']:.3f} | \"\n",
    "          f\"Health: {val_stats['acc_health']:.3f}\")\n",
    "    \n",
    "    # Save best model and check for improvement (based on health accuracy)\n",
    "    if val_stats[\"acc_health\"] > best_val_health:\n",
    "        best_val_health = val_stats[\"acc_health\"]\n",
    "        best_epoch = epoch\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"val_health\": best_val_health\n",
    "        }, \"best_multitask_mobilenet_v2.pt\")\n",
    "        print(f\"  ★ New best model saved! Val Health Acc: {best_val_health:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  No improvement. Epochs without improvement: {epochs_without_improvement}/{PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= PATIENCE:\n",
    "        print(f\"\\n{'EARLY STOPPING TRIGGERED':^80}\")\n",
    "        print(f\"No improvement for {PATIENCE} epochs. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best epoch: {best_epoch+1} with val_health={best_val_health:.4f}\")\n",
    "print(f\"Total epochs trained: {epoch+1}/{EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a16e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Test the best model\n",
    "# -------------------------------\n",
    "\n",
    "MODEL_NAME = \"best_multitask_mobilenet_v2.pt\"\n",
    "\n",
    "print(\"Testing best model on test set...\")\n",
    "checkpoint = torch.load(\"best_multitask_mobilenet_v2.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val_health={checkpoint['val_health']:.3f}\")\n",
    "\n",
    "# Running the test phase\n",
    "test_stats = run_epoch(test_loader, model, optimizer=None, train=False)\n",
    "print(f\"\\n{'TEST SET RESULTS':^80}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Loss: {test_stats['loss']:.4f}\")\n",
    "print(f\"  Species Accuracy: {test_stats['acc_species']:.4f} ({test_stats['acc_species']*100:.2f}%)\")\n",
    "print(f\"  Health Accuracy:  {test_stats['acc_health']:.4f} ({test_stats['acc_health']*100:.2f}%)\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Save final model\n",
    "torch.save({\"model\": model.state_dict(),\n",
    "            \"epoch\": EPOCHS - 1,\n",
    "            \"test_stats\": test_stats,\n",
    "            \"spec\": {\"species_map\": SPECIES_MAP, \"health_map\": HEALTH_MAP}},\n",
    "           \"final_multitask_mobilenet_v2.pt\")\n",
    "print(\"✓ Saved final model as 'final_multitask_mobilenet_v2.pt'\\n\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Final test phase (Additional)\n",
    "# -------------------------------\n",
    "print(\"=\"*80)\n",
    "print(\"Running Final Test\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_test_stats = run_epoch(test_loader, model, optimizer=None, train=False, epoch=EPOCHS-1)\n",
    "\n",
    "# Display Final Test Results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Test Results:\")\n",
    "print(f\"  loss: {final_test_stats['loss']:.4f} | species: {final_test_stats['acc_species']:.3f} | health: {final_test_stats['acc_health']:.3f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Summary & Visualizations\n",
    "# -------------------------------\n",
    "print(f\"\\nTraining completed for {MODEL_NAME}\")\n",
    "print(f\"Best validation health accuracy: {best_val_health:.3f}\")\n",
    "\n",
    "# Visualizations saved:\n",
    "print(f\"  - convergence_{MODEL_NAME.lower().replace('-', '_')}.png\")\n",
    "print(f\"  - lr_schedule_{MODEL_NAME.lower().replace('-', '_')}.png\")\n",
    "print(f\"  - history_{MODEL_NAME.lower().replace('-', '_')}.csv\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbeb98",
   "metadata": {},
   "source": [
    "## Plot saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Save Individual Training Plots\n",
    "# -------------------------------\n",
    "print(\"\\nGenerating individual training plots...\")\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# 1. Training Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_train_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_train_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Validation Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Validation Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Validation Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_val_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_val_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Train vs Val Loss Comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Val Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_loss_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_loss_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Species Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'r-o', label='Val Species Acc', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Species Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_species_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_species_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# 5. Health Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'b-o', label='Train Health Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'r-o', label='Val Health Acc', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Health/Disease Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_health_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_health_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# 6. All Accuracies Together (comprehensive view)\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'b--s', label='Val Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'g-o', label='Train Health', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'g--s', label='Val Health', linewidth=2, markersize=5)\n",
    "ax.axhline(y=best_val_health, color='r', linestyle='--', linewidth=2, label=f'Best Val Health: {best_val_health:.3f}')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('All Metrics Over Training', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_all_metrics.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_all_metrics.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All training plots saved:\")\n",
    "print(\"  - plot_train_loss.png\")\n",
    "print(\"  - plot_val_loss.png\")\n",
    "print(\"  - plot_loss_comparison.png\")\n",
    "print(\"  - plot_species_accuracy.png\")\n",
    "print(\"  - plot_health_accuracy.png\")\n",
    "print(\"  - plot_all_metrics.png\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82065d",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Comprehensive Testing Function\n",
    "# -------------------------------\n",
    "def comprehensive_test(model, test_loader, device, species_map, health_map):\n",
    "    \"\"\"\n",
    "    Perform comprehensive testing with metrics and visualizations\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Storage for predictions and ground truth\n",
    "    all_species_preds = []\n",
    "    all_species_true = []\n",
    "    all_health_preds = []\n",
    "    all_health_true = []\n",
    "    \n",
    "    print(\"Running comprehensive test evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, y_species, y_health) in enumerate(test_loader):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            y_species = y_species.to(device, non_blocking=True)\n",
    "            y_health = y_health.to(device, non_blocking=True)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits_species, logits_health = model(imgs)\n",
    "            preds_species = logits_species.argmax(dim=1)\n",
    "            preds_health = logits_health.argmax(dim=1)\n",
    "            \n",
    "            # Store predictions and ground truth\n",
    "            all_species_preds.extend(preds_species.cpu().numpy())\n",
    "            all_species_true.extend(y_species.cpu().numpy())\n",
    "            all_health_preds.extend(preds_health.cpu().numpy())\n",
    "            all_health_true.extend(y_health.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_species_preds = np.array(all_species_preds)\n",
    "    all_species_true = np.array(all_species_true)\n",
    "    all_health_preds = np.array(all_health_preds)\n",
    "    all_health_true = np.array(all_health_true)\n",
    "    \n",
    "    # Reverse mapping for labels\n",
    "    species_labels = {v: k.capitalize() for k, v in species_map.items()}\n",
    "    health_labels = {v: k.capitalize() for k, v in health_map.items()}\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Print Metrics\n",
    "    # -------------------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE TEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall accuracies\n",
    "    species_acc = accuracy_score(all_species_true, all_species_preds)\n",
    "    health_acc = accuracy_score(all_health_true, all_health_preds)\n",
    "    \n",
    "    print(f\"\\n{'OVERALL ACCURACIES':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Species Classification:  {species_acc:.4f} ({species_acc*100:.2f}%)\")\n",
    "    print(f\"  Health Classification:   {health_acc:.4f} ({health_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Species Classification Report\n",
    "    print(f\"\\n{'SPECIES CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_species_true, \n",
    "        all_species_preds,\n",
    "        target_names=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Health Classification Report\n",
    "    print(f\"\\n{'HEALTH/DISEASE CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_health_true, \n",
    "        all_health_preds,\n",
    "        target_names=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Visualizations\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Species confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_species = confusion_matrix(all_species_true, all_species_preds)\n",
    "    sns.heatmap(cm_species, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "                yticklabels=[species_labels[i] for i in sorted(species_labels.keys())])\n",
    "    ax.set_title(f'Species Classification\\nAccuracy: {species_acc:.2%}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_species.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved species confusion matrix to 'confusion_matrix_species.png'\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Health confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_health = confusion_matrix(all_health_true, all_health_preds)\n",
    "    sns.heatmap(cm_health, annot=True, fmt='d', cmap='Greens', ax=ax,\n",
    "                xticklabels=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "                yticklabels=[health_labels[i] for i in sorted(health_labels.keys())])\n",
    "    ax.set_title(f'Health/Disease Classification\\nAccuracy: {health_acc:.2%}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_health.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Saved health confusion matrix to 'confusion_matrix_health.png'\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Testing complete! Generated visualizations:\")\n",
    "    print(\"  - confusion_matrix_species.png\")\n",
    "    print(\"  - confusion_matrix_health.png\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'species_accuracy': species_acc,\n",
    "        'health_accuracy': health_acc,\n",
    "        'species_preds': all_species_preds,\n",
    "        'species_true': all_species_true,\n",
    "        'health_preds': all_health_preds,\n",
    "        'health_true': all_health_true\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Usage: Run after training\n",
    "# -------------------------------\n",
    "\n",
    "# Load the best model\n",
    "checkpoint = torch.load(\"best_multitask_mobilenet_v2.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val_health={checkpoint['val_health']:.3f}\")\n",
    "\n",
    "# Run comprehensive testing\n",
    "test_results = comprehensive_test(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    species_map=SPECIES_MAP,\n",
    "    health_map=HEALTH_MAP\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65226e",
   "metadata": {},
   "source": [
    "## 10 sample visualisation from 3 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Define your label mappings\n",
    "species_labels = {\n",
    "    0: 'Eggplant',\n",
    "    1: 'Potato',\n",
    "    2: 'Tomato'\n",
    "}\n",
    "\n",
    "health_labels = {\n",
    "    0: 'Bacterial',\n",
    "    1: 'Fungal',\n",
    "    2: 'Healthy',\n",
    "    3: 'Virus'\n",
    "}\n",
    "checkpoint = torch.load(\"best_multitask_mobilenet_v2.pt\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "# Number of samples to display per class\n",
    "amount = 10\n",
    "\n",
    "# Collect samples from validation set\n",
    "sample_images_by_class = {0: [], 1: [], 2: []}\n",
    "sample_predictions_by_class = {0: [], 1: [], 2: []}\n",
    "sample_ground_truth_by_class = {0: [], 1: [], 2: []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, species_batch, health_batch in val_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        species_preds = outputs[0].argmax(1)\n",
    "        health_preds = outputs[1].argmax(1)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            species_class = species_batch[i].item()\n",
    "            \n",
    "            if len(sample_images_by_class[species_class]) < amount:\n",
    "                sample_images_by_class[species_class].append(images[i].cpu())\n",
    "                sample_predictions_by_class[species_class].append({\n",
    "                    'species': species_preds[i].item(),\n",
    "                    'health': health_preds[i].item()\n",
    "                })\n",
    "                sample_ground_truth_by_class[species_class].append({\n",
    "                    'species': species_batch[i].item(),\n",
    "                    'health': health_batch[i].item()\n",
    "                })\n",
    "        \n",
    "        if all(len(samples) >= amount for samples in sample_images_by_class.values()):\n",
    "            break\n",
    "\n",
    "# Visualize\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "fig, axes = plt.subplots(3, amount, figsize=(3*amount, 9))\n",
    "\n",
    "for row, species_idx in enumerate(sorted(sample_images_by_class.keys())):\n",
    "    for col in range(amount):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        img = sample_images_by_class[species_idx][col]\n",
    "        pred = sample_predictions_by_class[species_idx][col]\n",
    "        gt = sample_ground_truth_by_class[species_idx][col]\n",
    "        \n",
    "        # Denormalize and display\n",
    "        img_display = img.numpy().transpose(1, 2, 0)\n",
    "        img_display = std * img_display + mean\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Check correctness\n",
    "        both_correct = (pred['species'] == gt['species']) and (pred['health'] == gt['health'])\n",
    "        \n",
    "        # Create title\n",
    "        pred_sp = species_labels[pred['species']]\n",
    "        pred_he = health_labels[pred['health']]\n",
    "        gt_sp = species_labels[gt['species']]\n",
    "        gt_he = health_labels[gt['health']]\n",
    "        \n",
    "        title = f\"Pred: {pred_sp}, {pred_he}\\nTrue: {gt_sp}, {gt_he}\"\n",
    "        color = 'green' if both_correct else 'red'\n",
    "        ax.set_title(title, fontsize=8, color=color, fontweight='bold')\n",
    "    \n",
    "    # Add species label\n",
    "    fig.text(0.02, 0.5 + (1 - row) * 0.3, species_labels[species_idx], \n",
    "             fontsize=12, fontweight='bold', va='center', rotation=90)\n",
    "\n",
    "plt.suptitle(f'Sample Predictions - {amount} Samples per Class\\n(Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 0.99])\n",
    "plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved sample predictions ({3*amount} total: {amount} per class) to 'sample_predictions.png'\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_classification1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

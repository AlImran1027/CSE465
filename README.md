# Plant Disease Classification using Multi-Task Learning

This project implements multi-task deep learning models for simultaneous plant species identification and disease classification using DenseNet architectures.

## ğŸ“‹ Project Overview

The system performs two classification tasks simultaneously:
1. **Species Classification**: Identifies the plant type (Eggplant, Potato, Tomato)
2. **Disease Classification**: Detects disease status (Bacterial, Fungal, Healthy, Virus)

## ğŸ—‚ï¸ Dataset Structure

The `Split_Dataset` directory contains images organized by plant species and health status:

```
Split_Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Eggplant_Bacterial/
â”‚   â”œâ”€â”€ Eggplant_Fungal/
â”‚   â”œâ”€â”€ Eggplant_Healthy/
â”‚   â”œâ”€â”€ Eggplant_Virus/
â”‚   â”œâ”€â”€ Potato_Bacterial/
â”‚   â”œâ”€â”€ Potato_Fungal/
â”‚   â”œâ”€â”€ Potato_Healthy/
â”‚   â”œâ”€â”€ Potato_Virus/
â”‚   â”œâ”€â”€ Tomato_Bacterial/
â”‚   â”œâ”€â”€ Tomato_Fungal/
â”‚   â”œâ”€â”€ Tomato_Healthy/
â”‚   â””â”€â”€ Tomato_Virus/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ [same structure as train]
â””â”€â”€ test/
    â””â”€â”€ [same structure as train]
```

**Label Mappings:**
- **Species**: `{eggplant: 0, potato: 1, tomato: 2}`
- **Health**: `{bacterial: 0, fungal: 1, healthy: 2, virus: 3}`

## ğŸ§  Models

### DenseNet121
- **File**: `Code files/DenseNet121-465.ipynb`
- **Architecture**: DenseNet121 with multi-task heads
- **Parameters**: ~7M trainable parameters
- **Model Output**: `best_multitask_DenseNet121.pt`

### DenseNet201
- **File**: `Code files/DenseNet201-465.ipynb`
- **Architecture**: DenseNet201 with multi-task heads
- **Parameters**: ~18M trainable parameters
- **Model Output**: `best_multitask_DenseNet201.pt`

## âš™ï¸ Configuration

Both models use the following configuration:

| Parameter | Value |
|-----------|-------|
| Image Size | 224Ã—224 |
| Batch Size | 32 |
| Learning Rate | 1e-4 |
| Optimizer | AdamW |
| Scheduler | CosineAnnealingLR |
| Dropout | 0.3 |
| Epochs | 10 (max) |
| Early Stopping | 3 epochs patience |
| Loss Function | CrossEntropyLoss (both tasks) |

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install torch torchvision
pip install pandas numpy
pip install matplotlib seaborn
pip install scikit-learn
pip install pillow opencv-python
pip install tqdm
```

### Running the Models

1. **Open Jupyter Notebook/Lab or VS Code**
   ```bash
   jupyter lab
   # or
   code .
   ```

2. **Select a model notebook**:
   - `DenseNet121-465.ipynb` for the lighter model
   - `DenseNet201-465.ipynb` for the heavier model

3. **Run cells sequentially**:
   - Cell 1: Imports
   - Cell 2: Visualization setup
   - Cell 3: Data loading and configuration
   - Cell 4: Model definition
   - Cell 5: Training loop
   - Cell 6: Testing and evaluation
   - Cell 7: Plot generation
   - Cell 8: Comprehensive metrics
   - Cell 9: Sample visualizations

## ğŸ“Š Output Files

After training, the following files will be generated:

### Model Checkpoints
- `best_multitask_DenseNet121.pt` / `best_multitask_DenseNet201.pt`
- `final_multitask_DenseNet121.pt` / `final_multitask_DenseNet201.pt`

### Training Plots
- `plot_train_loss.png` - Training loss over epochs
- `plot_val_loss.png` - Validation loss over epochs
- `plot_loss_comparison.png` - Train vs Val loss comparison
- `plot_species_accuracy.png` - Species classification accuracy
- `plot_health_accuracy.png` - Disease classification accuracy
- `plot_all_metrics.png` - All metrics combined

### Evaluation Results
- `confusion_matrix_species.png` - Species classification confusion matrix
- `confusion_matrix_health.png` - Disease classification confusion matrix
- `sample_predictions.png` - Sample predictions visualization (30 images)

## ğŸ“ˆ Model Architecture

```
Input (224Ã—224Ã—3)
    â†“
DenseNet Backbone (121 or 201 layers)
    â†“
Global Average Pooling
    â†“
Dropout (0.3)
    â†“
    â”œâ”€â†’ Species Head â†’ [3 classes]
    â””â”€â†’ Health Head â†’ [4 classes]
```

## ğŸ”¬ Training Features

- **Multi-Task Learning**: Joint training for species and disease classification
- **Data Augmentation**: Pre-applied offline augmentation
- **ImageNet Normalization**: Standard normalization for pretrained models
- **Mixed Precision Training**: Faster training with AMP (if CUDA available)
- **Gradient Clipping**: Prevents gradient explosion (max norm: 1.0)
- **Early Stopping**: Prevents overfitting
- **Learning Rate Scheduling**: Cosine annealing for better convergence

## ğŸ“‹ Evaluation Metrics

The notebooks compute and display:
- Overall accuracy (species and health separately)
- Per-class precision, recall, F1-score
- Confusion matrices with visualizations
- Classification reports

## ğŸ¯ Use Cases

- Agricultural disease diagnosis
- Automated plant health monitoring
- Research in plant pathology
- Educational tools for plant disease identification

## ğŸ“ Notes

- The notebooks use **CPU/MPS/CUDA** automatically based on availability
- Set `PRETRAINED = True` in configuration cell to use ImageNet pretrained weights
- Adjust `EPOCHS` and `BATCH_SIZE` based on your computational resources
- The dataset includes augmented images (identified by `_aug_` in filenames)

## ğŸ”§ Customization

To modify the training:

1. **Change hyperparameters**: Edit the configuration cell (Cell 3)
2. **Adjust model architecture**: Modify the model definition cell (Cell 4)
3. **Add new metrics**: Update the comprehensive testing function (Cell 8)
4. **Change visualization style**: Modify the TrainingLogger class (Cell 2)

## ğŸ“„ Files

```
CSE465/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ Code files/
â”‚   â”œâ”€â”€ DenseNet121-465.ipynb         # DenseNet121 implementation
â”‚   â””â”€â”€ DenseNet201-465.ipynb         # DenseNet201 implementation
â”œâ”€â”€ Split_Dataset/                     # Dataset directory
â”‚   â”œâ”€â”€ train/                        # Training set
â”‚   â”œâ”€â”€ val/                          # Validation set
â”‚   â””â”€â”€ test/                         # Test set
â””â”€â”€ [Generated outputs after training]
```

## ğŸ¤ Contributing

This is a course project (CSE465). Feel free to experiment with different architectures, hyperparameters, or augmentation strategies.

## ğŸ“§ Contact

For questions or issues related to this project, please refer to the course materials or contact the instructor.

---

**Last Updated**: December 2025  
**Course**: CSE465  
**Models**: DenseNet121, DenseNet201  
**Framework**: PyTorch

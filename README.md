# Plant Disease Multi-Task Classifier

Deep learning system for simultaneous plant species identification and disease detection with 20+ architectures, knowledge distillation, and explainable AI.

## Features

- ðŸŽ¯ **Multi-Task Learning**: Species (3) + Disease (4) classification
- ðŸ† **97%+ Accuracy**: DenseNet201 teacher model
- ðŸ“¦ **4.5x Compression**: Knowledge Distillation to EfficientNet-B0
- ðŸ” **Explainable AI**: Grad-CAM++ and LIME visualizations
- ðŸš€ **Production Ready**: End-to-end inference pipeline

## Dataset

**Classes**: 3 species (Eggplant, Potato, Tomato) Ã— 4 health (Bacterial, Fungal, Healthy, Virus) = 12 categories  
**Structure**: `Split_Dataset/{train,val,test}/{Species}_{Health}/`

## Models

### Performance

| Model | Params | Val Acc | Type |
|-------|--------|---------|------|
| **DenseNet201** â­ | 18.1M | 86.75%+ | Teacher |
| **EfficientNet-B0 + KD** | 4.0M | 84.31%+ | Student |
| DenseNet121 | 7.0M | 85%+ | CNN |
| MobileNetV2 | 2.2M | 77%+ | Mobile |

### Architectures (20+)

**CNNs**: DenseNet (121/201/264), ResNet (50/101/152), EfficientNetV2 (S/L), InceptionV3, Xception  
**Transformers**: ViT (B/L), DeiT (S/B), Swin (T/B/V2-L), Efficient-ViT  
**Lightweight**: MobileNet (V2/V3), EfficientNet-B0

## Quick Start

### Installation

```bash
pip install torch torchvision transformers timm kornia
pip install opencv-python pillow matplotlib seaborn scikit-learn lime
```

### Training

```bash
# Open a notebook and run all cells
jupyter lab CNN/DenseNet201-465.ipynb
```

### Inference

```python
from Model_inference.single_image_inference import predict

result = predict("plant_image.jpg")
# Output: Species, Health status, Confidence scores
```

### Knowledge Distillation

```bash
# Compress teacher to student model
jupyter lab KD/KD_model.ipynb
```

### Explainable AI

```bash
cd XAI && python xai_interpretability_465.py
# Generates Grad-CAM++ and LIME visualizations
```

## Output Files

**Models**: `best_DenseNet201.pt` (Teacher), `best_kd_student_efficientnetb0.pt` (KD Student)  
**Training Plots**: Loss curves, accuracy plots, confusion matrices, sample predictions  
**KD Plots**: KD-specific training visualizations  
**XAI**: Grad-CAM++ and LIME visualization outputs

## Training & Architecture

**Architecture**: Input â†’ DenseNet Backbone â†’ GAP â†’ Dropout â†’ Species Head (3) + Health Head (4)  
**Training**: Multi-task learning, ImageNet pre-training, data augmentation, mixed precision, gradient clipping, early stopping  
**Metrics**: Accuracy, precision, recall, F1-score, confusion matrices

## Use Cases

Agricultural diagnosis, IoT monitoring, research, mobile apps, education, production deployment

## Components

### Knowledge Distillation
**File**: `KD/KD_model.ipynb` | Teacher: DenseNet201 â†’ Student: EfficientNet-B0 | 4.5x compression, 96%+ accuracy

### Explainable AI
**File**: `XAI/xai_interpretability_465.py` | Methods: Grad-CAM++, LIME | Visualizes attention regions

### Inference Pipeline
**Files**: `bg_remove_465.py`, `image_unifier_v2.py`, `single_image_inference.py`  
**Flow**: RMBG background removal â†’ 224Ã—224 resize â†’ ImageNet normalization â†’ DenseNet201 prediction

```python
from Model_inference.single_image_inference import predict
result = predict("plant.jpg")
# Output: Species, Health, Confidence scores
```

## Project Structure

```
CSE465/
â”œâ”€â”€ CNN/                          # DenseNet, ResNet, EfficientNet, Inception, Xception
â”œâ”€â”€ Vision_Transformers/          # ViT, DeiT, Swin, Efficient-ViT
â”œâ”€â”€ Student_Models/               # MobileNet, EfficientNet-B0
â”œâ”€â”€ KD/                           # Knowledge Distillation (Teacherâ†’Student)
â”œâ”€â”€ Model_inference/              # Production inference pipeline
â”œâ”€â”€ XAI/                          # Grad-CAM++, LIME visualizations
â”œâ”€â”€ Split_Dataset/                # train/val/test splits
â”œâ”€â”€ best_DenseNet201.pt           # Best model (86.75%+ accuracy)
â””â”€â”€ requirements.txt
```

## Research

**Data Augmentation**: `Augmentation_465.ipynb` - Rotation, flipping, brightness/contrast  
**Architectures**: 20+ models (CNNs, Transformers, Lightweight)  
**Compression**: Knowledge Distillation (DenseNet201 â†’ EfficientNet-B0)  
**Explainability**: Grad-CAM++, LIME

## Technical Highlights

**Multi-Task Learning**: Joint species + disease classification with shared backbone  
**Transfer Learning**: ImageNet pre-training + fine-tuning  
**Model Compression**: 4.5x smaller via KD, 84%+ accuracy  
**Production Pipeline**: Background removal, preprocessing, device auto-detection  
**Interpretability**: Grad-CAM++ and LIME visualizations

## Key Insights

âœ… DenseNet201 best (86.75%+) | âœ… KD improves student by 1-2% | âœ… Background removal crucial  
âœ… Multi-task > separate models | âœ… Transfer learning essential

## Workflow

Data Augmentation â†’ Train Teacher (DenseNet201) â†’ Train Student â†’ Knowledge Distillation â†’ XAI Interpretation â†’ Production Deployment

## References

DenseNet (Huang 2017) | KD (Hinton 2015) | Grad-CAM++ (Chattopadhay 2018) | LIME (Ribeiro 2016) | ViT (Dosovitskiy 2021)

---

**CSE465 Deep Learning Project** | PyTorch | DenseNet201 (86.75%+) + EfficientNet-B0 (KD) | December 2025

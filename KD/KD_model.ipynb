{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf9fdc3",
   "metadata": {},
   "source": [
    "# Knowledge Distillation - DenseNet201 (Teacher) to EfficientNet-B0 (Student)\n",
    "\n",
    "**Teacher**: DenseNet201 (18.1M params) \n",
    "**Student**: EfficientNet-B0 (4.0M params)\n",
    "**Compression**: ~4.5x smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet201, DenseNet201_Weights, efficientnet_b0, EfficientNet_B0_Weights\n",
    "from PIL import Image\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9cb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_ROOT = Path(\"/Users/alimran/Desktop/CSE465/Split_Dataset\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  # Set to 0 for Jupyter notebooks to avoid multiprocessing issues\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "NUM_SPECIES = 3  # Eggplant, Potato, Tomato\n",
    "NUM_HEALTH = 4   # Bacterial, Fungal, Healthy, Virus\n",
    "DROPOUT = 0.3\n",
    "SEED = 42\n",
    "\n",
    "# KD-specific parameters\n",
    "TEMPERATURE = 4.0\n",
    "ALPHA = 0.7  # Weight for distillation loss (1-alpha for hard target loss)\n",
    "PATIENCE = 7  # Early stopping patience\n",
    "\n",
    "# Device setup - MPS for Mac, CUDA for NVIDIA, CPU fallback\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
    "                      \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "                      else \"cpu\")\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KNOWLEDGE DISTILLATION CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dataset:            Eggplant, Potato, Tomato (3 species)\")\n",
    "print(f\"Health Classes:     Bacterial, Fungal, Healthy, Virus (4 classes)\")\n",
    "print(f\"Data root:          {DATA_ROOT}\")\n",
    "print(f\"Device:             {device}\")\n",
    "print(f\"Batch Size:         {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate:      {LR}\")\n",
    "print(f\"Epochs:             {EPOCHS}\")\n",
    "print(f\"Patience:           {PATIENCE}\")\n",
    "print(f\"\\nKD Parameters:\")\n",
    "print(f\"Temperature:        {TEMPERATURE}\")\n",
    "print(f\"Alpha (KD weight):  {ALPHA}\")\n",
    "print(f\"Random Seed:        {SEED}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4579b42",
   "metadata": {},
   "source": [
    "## Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set publication-quality style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 100  # Lower for notebook display, saved figures will be 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "class TrainingLogger:\n",
    "    \"\"\"Logger to track training metrics epoch-by-epoch\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'train_acc_species': [],\n",
    "            'val_acc_species': [],\n",
    "            'train_acc_health': [],\n",
    "            'val_acc_health': [],\n",
    "            'train_acc_both': [],\n",
    "            'val_acc_both': [],\n",
    "            'lr': []\n",
    "        }\n",
    "    \n",
    "    def log_epoch(self, epoch, train_stats, val_stats, lr):\n",
    "        \"\"\"Log metrics for one epoch\"\"\"\n",
    "        self.history['epoch'].append(epoch)\n",
    "        self.history['train_loss'].append(train_stats['loss'])\n",
    "        self.history['val_loss'].append(val_stats['loss'])\n",
    "        self.history['train_acc_species'].append(train_stats['acc_species'])\n",
    "        self.history['val_acc_species'].append(val_stats['acc_species'])\n",
    "        self.history['train_acc_health'].append(train_stats['acc_health'])\n",
    "        self.history['val_acc_health'].append(val_stats['acc_health'])\n",
    "        self.history['train_acc_both'].append(train_stats['acc_both'])\n",
    "        self.history['val_acc_both'].append(val_stats['acc_both'])\n",
    "        self.history['lr'].append(lr)\n",
    "    \n",
    "    def plot_convergence(self, save_path='training_convergence.png', model_name='Model', show=True):\n",
    "        \"\"\"\n",
    "        Create publication-quality convergence plots\n",
    "        \n",
    "        Args:\n",
    "            save_path: Path to save the figure\n",
    "            model_name: Name of the model for the title\n",
    "            show: Whether to display the plot in notebook (default: True)\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(f'{model_name} Training Convergence', fontsize=14, fontweight='bold', y=0.995)\n",
    "        \n",
    "        epochs = self.history['epoch']\n",
    "        \n",
    "        # Plot 1: Training and Validation Loss\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(epochs, self.history['train_loss'], 'o-', label='Train Loss', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax1.plot(epochs, self.history['val_loss'], 's-', label='Val Loss', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('(a) Multi-task Loss', fontweight='bold', loc='left')\n",
    "        ax1.legend(framealpha=0.9)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Species Accuracy\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(epochs, self.history['train_acc_species'], 'o-', label='Train Species', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax2.plot(epochs, self.history['val_acc_species'], 's-', label='Val Species', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('(b) Species Classification', fontweight='bold', loc='left')\n",
    "        ax2.set_ylim([0, 1.05])\n",
    "        ax2.legend(framealpha=0.9)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Disease Accuracy\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(epochs, self.history['train_acc_health'], 'o-', label='Train Disease', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax3.plot(epochs, self.history['val_acc_health'], 's-', label='Val Disease', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        ax3.set_xlabel('Epoch')\n",
    "        ax3.set_ylabel('Accuracy')\n",
    "        ax3.set_title('(c) Disease Detection', fontweight='bold', loc='left')\n",
    "        ax3.set_ylim([0, 1.05])\n",
    "        ax3.legend(framealpha=0.9)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Joint Accuracy (Both Correct)\n",
    "        ax4 = axes[1, 1]\n",
    "        ax4.plot(epochs, self.history['train_acc_both'], 'o-', label='Train Both', \n",
    "                linewidth=2, markersize=4, color='#2E86AB', alpha=0.8)\n",
    "        ax4.plot(epochs, self.history['val_acc_both'], 's-', label='Val Both', \n",
    "                linewidth=2, markersize=4, color='#A23B72', alpha=0.8)\n",
    "        \n",
    "        # Mark best validation epoch\n",
    "        if len(self.history['val_acc_both']) > 0:\n",
    "            best_epoch_idx = np.argmax(self.history['val_acc_both'])\n",
    "            best_epoch = epochs[best_epoch_idx]\n",
    "            best_val_both = self.history['val_acc_both'][best_epoch_idx]\n",
    "            ax4.axvline(x=best_epoch, color='red', linestyle='--', \n",
    "                       linewidth=1.5, alpha=0.6, label=f'Best (Epoch {best_epoch})')\n",
    "            ax4.plot(best_epoch, best_val_both, 'r*', markersize=15, \n",
    "                    markeredgecolor='darkred', markeredgewidth=1.5)\n",
    "            \n",
    "            # Add annotation for best performance\n",
    "            ax4.annotate(f'{best_val_both:.3f}', \n",
    "                        xy=(best_epoch, best_val_both),\n",
    "                        xytext=(10, -15), textcoords='offset points',\n",
    "                        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),\n",
    "                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0', color='red'),\n",
    "                        fontsize=9, fontweight='bold')\n",
    "        \n",
    "        ax4.set_xlabel('Epoch')\n",
    "        ax4.set_ylabel('Accuracy')\n",
    "        ax4.set_title('(d) Joint Accuracy (Primary Metric)', fontweight='bold', loc='left')\n",
    "        ax4.set_ylim([0, 1.05])\n",
    "        ax4.legend(framealpha=0.9)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Convergence plot saved to: {save_path}\")\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def plot_learning_rate(self, save_path='learning_rate_schedule.png', show=True):\n",
    "        \"\"\"Plot learning rate schedule\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        \n",
    "        epochs = self.history['epoch']\n",
    "        ax.plot(epochs, self.history['lr'], 'o-', linewidth=2, \n",
    "               markersize=5, color='#F18F01', label='Learning Rate')\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate')\n",
    "        ax.set_title('Learning Rate Schedule (Cosine Annealing)', fontweight='bold')\n",
    "        ax.legend(framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Learning rate plot saved to: {save_path}\")\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def save_history(self, save_path='training_history.csv'):\n",
    "        \"\"\"Save training history to CSV\"\"\"\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(self.history)\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"✓ Training history saved to: {save_path}\")\n",
    "\n",
    "print(\"✓ TrainingLogger class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mappings (updated for CSE465 project)\n",
    "SPECIES_MAP = {\"eggplant\": 0, \"potato\": 1, \"tomato\": 2}\n",
    "HEALTH_MAP = {\"bacterial\": 0, \"fungal\": 1, \"healthy\": 2, \"virus\": 3}\n",
    "\n",
    "def parse_joint_label(folder_name: str) -> Tuple[int, int]:\n",
    "    \"\"\"Parse folder name like 'Eggplant_Healthy' into (species_id, health_id)\"\"\"\n",
    "    name = folder_name.strip()\n",
    "    if \"_\" not in name:\n",
    "        raise ValueError(f\"Folder name not joint label: {name}\")\n",
    "    sp, he = name.split(\"_\", 1)\n",
    "    sp_id = SPECIES_MAP[sp.lower()]\n",
    "    he_id = HEALTH_MAP[he.lower()]\n",
    "    return sp_id, he_id\n",
    "\n",
    "# Dataset class\n",
    "class JointLeafDataset(Dataset):\n",
    "    \"\"\"Dataset that returns separate species and health labels\"\"\"\n",
    "    def __init__(self, split_root: Path, transform=None):\n",
    "        self.split_root = Path(split_root)\n",
    "        self.samples: List[Tuple[str, int, int]] = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        for folder in sorted([d for d in self.split_root.iterdir() if d.is_dir()]):\n",
    "            sp_id, he_id = parse_joint_label(folder.name)\n",
    "            for p in folder.rglob(\"*\"):\n",
    "                if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}:\n",
    "                    self.samples.append((str(p), sp_id, he_id))\n",
    "        \n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(f\"No images found under {split_root}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, sp_id, he_id = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, torch.tensor(sp_id, dtype=torch.long), torch.tensor(he_id, dtype=torch.long)\n",
    "\n",
    "# Data transforms (ImageNet normalization for pretrained models)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = JointLeafDataset(DATA_ROOT / \"train\", transform=transform)\n",
    "val_dataset = JointLeafDataset(DATA_ROOT / \"val\", transform=transform)\n",
    "test_dataset = JointLeafDataset(DATA_ROOT / \"test\", transform=transform)\n",
    "\n",
    "print(f\"Training samples:   {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples:       {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "print(\"✓ Datasets and loaders ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architectures (updated for CSE465)\n",
    "\n",
    "class MultiTaskDenseNet201(nn.Module):\n",
    "    \"\"\"DenseNet201 (TEACHER) with separate species and health classification heads\"\"\"\n",
    "    def __init__(self, num_species=3, num_health=4, pretrained=False, dropout=0.3):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            weights = DenseNet201_Weights.IMAGENET1K_V1\n",
    "            self.backbone = densenet201(weights=weights)\n",
    "        else:\n",
    "            self.backbone = densenet201(weights=None)\n",
    "        \n",
    "        # DenseNet201 has classifier as a single Linear layer, not a Sequential\n",
    "        in_dim = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head_species = nn.Linear(in_dim, num_species)\n",
    "        self.head_health = nn.Linear(in_dim, num_health)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.dropout(feats)\n",
    "        logits_species = self.head_species(feats)\n",
    "        logits_health = self.head_health(feats)\n",
    "        return logits_species, logits_health\n",
    "\n",
    "\n",
    "class MultiTaskEfficientNetB0(nn.Module):\n",
    "    \"\"\"EfficientNet-B0 (STUDENT) with separate species and health classification heads\"\"\"\n",
    "    def __init__(self, num_species=3, num_health=4, pretrained=False, dropout=0.3):\n",
    "        super().__init__()\n",
    "        if pretrained:\n",
    "            weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "            self.backbone = efficientnet_b0(weights=weights)\n",
    "        else:\n",
    "            self.backbone = efficientnet_b0(weights=None)\n",
    "        \n",
    "        # EfficientNetB0 has classifier as a Sequential with dropout and linear layer\n",
    "        in_dim = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head_species = nn.Linear(in_dim, num_species)\n",
    "        self.head_health = nn.Linear(in_dim, num_health)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        feats = self.dropout(feats)\n",
    "        logits_species = self.head_species(feats)\n",
    "        logits_health = self.head_health(feats)\n",
    "        return logits_species, logits_health\n",
    "\n",
    "print(\"✓ Model classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models\n",
    "print(\"=\"*80)\n",
    "print(\"Loading Pre-Trained Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== TEACHER (DenseNet201) ==========\n",
    "print(\"\\n[1/2] Loading Teacher Model (DenseNet201)...\")\n",
    "teacher_path = '/Users/alimran/Desktop/CSE465/best_DenseNet201.pt'\n",
    "\n",
    "teacher = MultiTaskDenseNet201(num_species=NUM_SPECIES, num_health=NUM_HEALTH, dropout=DROPOUT)\n",
    "teacher_checkpoint = torch.load(teacher_path, map_location=device, weights_only=False)\n",
    "\n",
    "teacher.load_state_dict(teacher_checkpoint[\"model\"])\n",
    "teacher.to(device)\n",
    "teacher.eval()  # Set to evaluation mode\n",
    "for param in teacher.parameters():\n",
    "    param.requires_grad = False  # Freeze teacher\n",
    "\n",
    "teacher_epoch = teacher_checkpoint.get('epoch', 'N/A')\n",
    "teacher_val_acc = teacher_checkpoint.get('val_health', 0.0)\n",
    "\n",
    "print(f\"✓ Teacher loaded successfully\")\n",
    "print(f\"  Model: DenseNet201\")\n",
    "print(f\"  Path: {teacher_path}\")\n",
    "print(f\"  Trained Epoch: {teacher_epoch}\")\n",
    "print(f\"  Val Health Acc: {teacher_val_acc:.4f}\")\n",
    "\n",
    "# ========== STUDENT (EfficientNet-B0) ==========\n",
    "print(\"\\n[2/2] Loading Student Model (EfficientNet-B0)...\")\n",
    "student_path = '/Users/alimran/Desktop/CSE465/best_multitask_efficientnet_b0 (1).pt'\n",
    "\n",
    "student = MultiTaskEfficientNetB0(num_species=NUM_SPECIES, num_health=NUM_HEALTH, dropout=DROPOUT)\n",
    "student_checkpoint = torch.load(student_path, map_location=device, weights_only=False)\n",
    "\n",
    "student.load_state_dict(student_checkpoint[\"model\"])\n",
    "student.to(device)\n",
    "student.train()  # Set to training mode (will be fine-tuned with KD)\n",
    "\n",
    "student_epoch = student_checkpoint.get('epoch', 'N/A')\n",
    "student_val_acc = student_checkpoint.get('val_health', 0.0)\n",
    "\n",
    "print(f\"✓ Student loaded successfully\")\n",
    "print(f\"  Model: EfficientNet-B0\")\n",
    "print(f\"  Path: {student_path}\")\n",
    "print(f\"  Trained Epoch: {student_epoch}\")\n",
    "print(f\"  Val Health Acc (before KD): {student_val_acc:.4f}\")\n",
    "\n",
    "# ========== MODEL STATISTICS ==========\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "student_params = sum(p.numel() for p in student.parameters())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Teacher Parameters:  {teacher_params:,}\")\n",
    "print(f\"Student Parameters:  {student_params:,}\")\n",
    "print(f\"Compression Ratio:   {teacher_params/student_params:.2f}x\")\n",
    "print(f\"Size Reduction:      {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Distillation Loss Function\n",
    "def kd_loss(student_outputs, teacher_outputs, labels_species, labels_health, \n",
    "            temperature=4.0, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Knowledge Distillation loss for multitask learning\n",
    "    \n",
    "    Args:\n",
    "        student_outputs: tuple (species_logits, health_logits) from student\n",
    "        teacher_outputs: tuple (species_logits, health_logits) from teacher\n",
    "        labels_species: ground truth species labels\n",
    "        labels_health: ground truth health labels\n",
    "        temperature: softening temperature for distillation\n",
    "        alpha: weight for distillation loss (1-alpha for hard target loss)\n",
    "    \n",
    "    Returns:\n",
    "        Combined KD loss\n",
    "    \"\"\"\n",
    "    student_species, student_health = student_outputs\n",
    "    teacher_species, teacher_health = teacher_outputs\n",
    "    \n",
    "    # Distillation loss for species (soft targets from teacher)\n",
    "    soft_targets_species = F.softmax(teacher_species / temperature, dim=1)\n",
    "    soft_prob_species = F.log_softmax(student_species / temperature, dim=1)\n",
    "    distill_loss_species = F.kl_div(soft_prob_species, soft_targets_species, \n",
    "                                     reduction='batchmean') * (temperature ** 2)\n",
    "    \n",
    "    # Distillation loss for health (soft targets from teacher)\n",
    "    soft_targets_health = F.softmax(teacher_health / temperature, dim=1)\n",
    "    soft_prob_health = F.log_softmax(student_health / temperature, dim=1)\n",
    "    distill_loss_health = F.kl_div(soft_prob_health, soft_targets_health, \n",
    "                                    reduction='batchmean') * (temperature ** 2)\n",
    "    \n",
    "    # Hard target loss (ground truth)\n",
    "    hard_loss_species = F.cross_entropy(student_species, labels_species)\n",
    "    hard_loss_health = F.cross_entropy(student_health, labels_health)\n",
    "    \n",
    "    # Combined losses\n",
    "    distillation_loss = (distill_loss_species + distill_loss_health) / 2\n",
    "    hard_loss = (hard_loss_species + hard_loss_health) / 2\n",
    "    \n",
    "    # Final KD loss\n",
    "    total_loss = alpha * distillation_loss + (1 - alpha) * hard_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "print(\"✓ KD loss function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=LR, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR/100)\n",
    "\n",
    "# Initialize TrainingLogger\n",
    "logger = TrainingLogger()\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    \"train_loss\": [], \"val_loss\": [],\n",
    "    \"train_acc_species\": [], \"val_acc_species\": [],\n",
    "    \"train_acc_health\": [], \"val_acc_health\": [],\n",
    "    \"train_acc_both\": [], \"val_acc_both\": []\n",
    "}\n",
    "\n",
    "best_val_health = student_val_acc  # Start from pre-trained performance\n",
    "best_epoch = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SETUP COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Optimizer:           AdamW\")\n",
    "print(f\"Scheduler:           CosineAnnealingLR\")\n",
    "print(f\"Starting Val Health: {best_val_health:.4f} (from pre-trained student)\")\n",
    "print(f\"Target:              Improve via Knowledge Distillation\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d587a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with Knowledge Distillation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING KNOWLEDGE DISTILLATION TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ========== TRAINING PHASE ==========\n",
    "    student.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct_species = 0\n",
    "    train_correct_health = 0\n",
    "    train_correct_both = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    for imgs, y_species, y_health in tqdm(train_loader, desc=\"Train\"):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        y_species = y_species.to(device, non_blocking=True)\n",
    "        y_health = y_health.to(device, non_blocking=True)\n",
    "        \n",
    "        batch_size = imgs.size(0)\n",
    "        \n",
    "        # Get teacher predictions (no gradient)\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(imgs)\n",
    "        \n",
    "        # Get student predictions\n",
    "        student_outputs = student(imgs)\n",
    "        \n",
    "        # Calculate KD loss\n",
    "        loss = kd_loss(student_outputs, teacher_outputs, y_species, y_health, \n",
    "                      temperature=TEMPERATURE, alpha=ALPHA)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        student_species, student_health = student_outputs\n",
    "        preds_species = student_species.argmax(dim=1)\n",
    "        preds_health = student_health.argmax(dim=1)\n",
    "        \n",
    "        train_correct_species += (preds_species == y_species).sum().item()\n",
    "        train_correct_health += (preds_health == y_health).sum().item()\n",
    "        both_correct = (preds_species == y_species) & (preds_health == y_health)\n",
    "        train_correct_both += both_correct.sum().item()\n",
    "        \n",
    "        train_loss += loss.item() * batch_size\n",
    "        train_total += batch_size\n",
    "    \n",
    "    # Training metrics\n",
    "    train_loss_avg = train_loss / train_total\n",
    "    train_acc_species = train_correct_species / train_total\n",
    "    train_acc_health = train_correct_health / train_total\n",
    "    train_acc_both = train_correct_both / train_total\n",
    "    \n",
    "    history[\"train_loss\"].append(train_loss_avg)\n",
    "    history[\"train_acc_species\"].append(train_acc_species)\n",
    "    history[\"train_acc_health\"].append(train_acc_health)\n",
    "    history[\"train_acc_both\"].append(train_acc_both)\n",
    "    \n",
    "    # ========== VALIDATION PHASE ==========\n",
    "    student.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct_species = 0\n",
    "    val_correct_health = 0\n",
    "    val_correct_both = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    print(\"Validating...\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, y_species, y_health in tqdm(val_loader, desc=\"Val\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            y_species = y_species.to(device, non_blocking=True)\n",
    "            y_health = y_health.to(device, non_blocking=True)\n",
    "            \n",
    "            batch_size = imgs.size(0)\n",
    "            \n",
    "            # Get predictions\n",
    "            teacher_outputs = teacher(imgs)\n",
    "            student_outputs = student(imgs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = kd_loss(student_outputs, teacher_outputs, y_species, y_health, \n",
    "                          temperature=TEMPERATURE, alpha=ALPHA)\n",
    "            \n",
    "            # Calculate accuracies\n",
    "            student_species, student_health = student_outputs\n",
    "            preds_species = student_species.argmax(dim=1)\n",
    "            preds_health = student_health.argmax(dim=1)\n",
    "            \n",
    "            val_correct_species += (preds_species == y_species).sum().item()\n",
    "            val_correct_health += (preds_health == y_health).sum().item()\n",
    "            both_correct = (preds_species == y_species) & (preds_health == y_health)\n",
    "            val_correct_both += both_correct.sum().item()\n",
    "            \n",
    "            val_loss += loss.item() * batch_size\n",
    "            val_total += batch_size\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_loss_avg = val_loss / val_total\n",
    "    val_acc_species = val_correct_species / val_total\n",
    "    val_acc_health = val_correct_health / val_total\n",
    "    val_acc_both = val_correct_both / val_total\n",
    "    \n",
    "    history[\"val_loss\"].append(val_loss_avg)\n",
    "    history[\"val_acc_species\"].append(val_acc_species)\n",
    "    history[\"val_acc_health\"].append(val_acc_health)\n",
    "    history[\"val_acc_both\"].append(val_acc_both)\n",
    "    \n",
    "    # Log to TrainingLogger\n",
    "    train_stats = {\n",
    "        'loss': train_loss_avg,\n",
    "        'acc_species': train_acc_species,\n",
    "        'acc_health': train_acc_health,\n",
    "        'acc_both': train_acc_both\n",
    "    }\n",
    "    val_stats = {\n",
    "        'loss': val_loss_avg,\n",
    "        'acc_species': val_acc_species,\n",
    "        'acc_health': val_acc_health,\n",
    "        'acc_both': val_acc_both\n",
    "    }\n",
    "    logger.log_epoch(epoch+1, train_stats, val_stats, optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'EPOCH SUMMARY':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Train - Loss: {train_loss_avg:.4f} | Species: {train_acc_species:.3f} | \"\n",
    "          f\"Health: {train_acc_health:.3f} | Both: {train_acc_both:.3f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss_avg:.4f} | Species: {val_acc_species:.3f} | \"\n",
    "          f\"Health: {val_acc_health:.3f} | Both: {val_acc_both:.3f}\")\n",
    "    \n",
    "    # Save best model (based on health accuracy)\n",
    "    if val_acc_health > best_val_health:\n",
    "        best_val_health = val_acc_health\n",
    "        best_epoch = epoch\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save({\n",
    "            \"model\": student.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"val_health\": best_val_health,\n",
    "            \"val_species\": val_acc_species,\n",
    "            \"val_both\": val_acc_both,\n",
    "            \"history\": history\n",
    "        }, \"/Users/alimran/Desktop/CSE465/best_kd_student_efficientnetb0.pt\")\n",
    "        print(f\"  ★ New best model saved! Val Health Acc: {best_val_health:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  No improvement. Epochs without improvement: {epochs_without_improvement}/{PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= PATIENCE:\n",
    "        print(f\"\\n{'⚠ EARLY STOPPING TRIGGERED':^80}\")\n",
    "        print(f\"No improvement for {PATIENCE} epochs. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KNOWLEDGE DISTILLATION TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best epoch: {best_epoch+1} with val_health={best_val_health:.4f}\")\n",
    "print(f\"Total epochs trained: {epoch+1}/{EPOCHS}\")\n",
    "print(f\"Improvement over pre-trained: {(best_val_health - student_val_acc)*100:.2f}%\")\n",
    "print(f\"Model saved to: best_kd_student_efficientnetb0.pt\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf974c",
   "metadata": {},
   "source": [
    "## Plot Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf2480",
   "metadata": {},
   "source": [
    "## Final Testing & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all three models: Teacher, Pre-trained Student, KD Student\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE TESTING - TEACHER vs STUDENT (Before/After KD)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate_model(model, loader, model_name):\n",
    "    \"\"\"Evaluate a model on the test set\"\"\"\n",
    "    model.eval()\n",
    "    correct_species = 0\n",
    "    correct_health = 0\n",
    "    correct_both = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, y_species, y_health in tqdm(loader, desc=f\"Testing {model_name}\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            y_species = y_species.to(device, non_blocking=True)\n",
    "            y_health = y_health.to(device, non_blocking=True)\n",
    "            \n",
    "            logits_species, logits_health = model(imgs)\n",
    "            preds_species = logits_species.argmax(dim=1)\n",
    "            preds_health = logits_health.argmax(dim=1)\n",
    "            \n",
    "            correct_species += (preds_species == y_species).sum().item()\n",
    "            correct_health += (preds_health == y_health).sum().item()\n",
    "            both_correct = (preds_species == y_species) & (preds_health == y_health)\n",
    "            correct_both += both_correct.sum().item()\n",
    "            \n",
    "            total += imgs.size(0)\n",
    "    \n",
    "    return {\n",
    "        'species': correct_species / total,\n",
    "        'health': correct_health / total,\n",
    "        'both': correct_both / total\n",
    "    }\n",
    "\n",
    "# Load pre-trained student (before KD) for comparison\n",
    "pretrained_student = MultiTaskEfficientNetB0(num_species=NUM_SPECIES, num_health=NUM_HEALTH, dropout=DROPOUT)\n",
    "pretrained_checkpoint = torch.load('/Users/alimran/Desktop/CSE465/best_multitask_efficientnet_b0 (1).pt', \n",
    "                                   map_location=device, weights_only=False)\n",
    "pretrained_student.load_state_dict(pretrained_checkpoint[\"model\"])\n",
    "pretrained_student.to(device)\n",
    "pretrained_student.eval()\n",
    "\n",
    "# Load KD-trained student\n",
    "kd_student = MultiTaskEfficientNetB0(num_species=NUM_SPECIES, num_health=NUM_HEALTH, dropout=DROPOUT)\n",
    "kd_checkpoint = torch.load('/Users/alimran/Desktop/CSE465/best_kd_student_efficientnetb0.pt', \n",
    "                           map_location=device, weights_only=False)\n",
    "kd_student.load_state_dict(kd_checkpoint[\"model\"])\n",
    "kd_student.to(device)\n",
    "kd_student.eval()\n",
    "\n",
    "# Test all three models\n",
    "print(\"\\n[1/3] Testing Teacher (DenseNet201)...\")\n",
    "teacher_results = evaluate_model(teacher, test_loader, \"Teacher\")\n",
    "\n",
    "print(\"\\n[2/3] Testing Pre-trained Student (EfficientNet-B0)...\")\n",
    "pretrained_results = evaluate_model(pretrained_student, test_loader, \"Pre-trained Student\")\n",
    "\n",
    "print(\"\\n[3/3] Testing KD Student (EfficientNet-B0 + Knowledge Distillation)...\")\n",
    "kd_results = evaluate_model(kd_student, test_loader, \"KD Student\")\n",
    "\n",
    "# Display comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<40} {'Species':<12} {'Health':<12} {'Both':<12} {'Params':<15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Teacher (DenseNet201)':<40} {teacher_results['species']:.4f}      {teacher_results['health']:.4f}      {teacher_results['both']:.4f}      {teacher_params:,}\")\n",
    "print(f\"{'Student (EfficientNet-B0)':<40} {pretrained_results['species']:.4f}      {pretrained_results['health']:.4f}      {pretrained_results['both']:.4f}      {student_params:,}\")\n",
    "print(f\"{'KD Student (EfficientNet-B0 + KD)':<40} {kd_results['species']:.4f}      {kd_results['health']:.4f}      {kd_results['both']:.4f}      {student_params:,}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate improvements\n",
    "health_improvement = (kd_results['health'] - pretrained_results['health']) * 100\n",
    "both_improvement = (kd_results['both'] - pretrained_results['both']) * 100\n",
    "teacher_gap_before = (teacher_results['health'] - pretrained_results['health']) * 100\n",
    "teacher_gap_after = (teacher_results['health'] - kd_results['health']) * 100\n",
    "\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"1. KD Improvement (Health Acc):    {health_improvement:+.2f}%\")\n",
    "print(f\"2. KD Improvement (Both Acc):      {both_improvement:+.2f}%\")\n",
    "print(f\"3. Gap to Teacher (Before KD):     {teacher_gap_before:.2f}%\")\n",
    "print(f\"4. Gap to Teacher (After KD):      {teacher_gap_after:.2f}%\")\n",
    "print(f\"5. Model Size Reduction:           {(1 - student_params/teacher_params)*100:.1f}%\")\n",
    "print(f\"6. Compression Ratio:              {teacher_params/student_params:.2f}x smaller\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Save Individual Training Plots\n",
    "# -------------------------------\n",
    "print(\"\\nGenerating Knowledge Distillation training plots...\")\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# 1. Training Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_train_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_train_loss.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 2. Validation Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Validation Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Validation Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_val_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_val_loss.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 3. Train vs Val Loss Comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Val Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_loss_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_loss_comparison.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 4. Species Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'r-o', label='Val Species Acc', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Species Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_species_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_species_accuracy.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 5. Health Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'b-o', label='Train Health Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'r-o', label='Val Health Acc', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Health/Disease Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_health_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_health_accuracy.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 6. Joint (Both) Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_both'], 'b-o', label='Train Both Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_both'], 'r-o', label='Val Both Acc', linewidth=2, markersize=6)\n",
    "if best_val_health > 0:\n",
    "    ax.axhline(y=best_val_health, color='g', linestyle='--', linewidth=2, \n",
    "               label=f'Best Val Health: {best_val_health:.3f}')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - Joint Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_joint_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_joint_accuracy.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 7. All Accuracies Together\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'b--s', label='Val Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'g-o', label='Train Health', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'g--s', label='Val Health', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['train_acc_both'], 'r-o', label='Train Both', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_both'], 'r--s', label='Val Both', linewidth=2, markersize=5)\n",
    "if best_val_health > 0:\n",
    "    ax.axhline(y=best_val_health, color='orange', linestyle='--', linewidth=2, \n",
    "               label=f'Best: {best_val_health:.3f}')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Knowledge Distillation - All Metrics Over Training', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('kd_plot_all_metrics.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved kd_plot_all_metrics.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All KD training plots saved:\")\n",
    "print(\"  - kd_plot_train_loss.png\")\n",
    "print(\"  - kd_plot_val_loss.png\")\n",
    "print(\"  - kd_plot_loss_comparison.png\")\n",
    "print(\"  - kd_plot_species_accuracy.png\")\n",
    "print(\"  - kd_plot_health_accuracy.png\")\n",
    "print(\"  - kd_plot_joint_accuracy.png\")\n",
    "print(\"  - kd_plot_all_metrics.png\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf36c1",
   "metadata": {},
   "source": [
    "## Comprehensive Testing with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics libraries\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Comprehensive Testing Function\n",
    "# -------------------------------\n",
    "def comprehensive_test(model, test_loader, device, species_map, health_map):\n",
    "    \"\"\"\n",
    "    Perform comprehensive testing with metrics and visualizations\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Storage for predictions and ground truth\n",
    "    all_species_preds = []\n",
    "    all_species_true = []\n",
    "    all_health_preds = []\n",
    "    all_health_true = []\n",
    "    all_both_correct = []\n",
    "    \n",
    "    print(\"Running comprehensive test evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, y_species, y_health) in enumerate(test_loader):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            y_species = y_species.to(device, non_blocking=True)\n",
    "            y_health = y_health.to(device, non_blocking=True)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits_species, logits_health = model(imgs)\n",
    "            preds_species = logits_species.argmax(dim=1)\n",
    "            preds_health = logits_health.argmax(dim=1)\n",
    "            \n",
    "            # Store predictions and ground truth\n",
    "            all_species_preds.extend(preds_species.cpu().numpy())\n",
    "            all_species_true.extend(y_species.cpu().numpy())\n",
    "            all_health_preds.extend(preds_health.cpu().numpy())\n",
    "            all_health_true.extend(y_health.cpu().numpy())\n",
    "            \n",
    "            # Check if both predictions are correct\n",
    "            both_correct = ((preds_species == y_species) & (preds_health == y_health)).cpu().numpy()\n",
    "            all_both_correct.extend(both_correct)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_species_preds = np.array(all_species_preds)\n",
    "    all_species_true = np.array(all_species_true)\n",
    "    all_health_preds = np.array(all_health_preds)\n",
    "    all_health_true = np.array(all_health_true)\n",
    "    all_both_correct = np.array(all_both_correct)\n",
    "    \n",
    "    # Reverse mapping for labels\n",
    "    species_labels = {v: k.capitalize() for k, v in species_map.items()}\n",
    "    health_labels = {v: k.capitalize() for k, v in health_map.items()}\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Print Metrics\n",
    "    # -------------------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE TEST RESULTS - KNOWLEDGE DISTILLATION STUDENT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall accuracies\n",
    "    species_acc = accuracy_score(all_species_true, all_species_preds)\n",
    "    health_acc = accuracy_score(all_health_true, all_health_preds)\n",
    "    both_acc = all_both_correct.mean()\n",
    "    \n",
    "    print(f\"\\n{'OVERALL ACCURACIES':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Species Classification:  {species_acc:.4f} ({species_acc*100:.2f}%)\")\n",
    "    print(f\"  Health Classification:   {health_acc:.4f} ({health_acc*100:.2f}%)\")\n",
    "    print(f\"  Both Correct (Joint):    {both_acc:.4f} ({both_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Species Classification Report\n",
    "    print(f\"\\n{'SPECIES CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_species_true, \n",
    "        all_species_preds,\n",
    "        target_names=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Health Classification Report\n",
    "    print(f\"\\n{'HEALTH/DISEASE CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_health_true, \n",
    "        all_health_preds,\n",
    "        target_names=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Per-class joint accuracy\n",
    "    print(f\"\\n{'PER-CLASS JOINT ACCURACY':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    for sp_id in sorted(species_labels.keys()):\n",
    "        for he_id in sorted(health_labels.keys()):\n",
    "            # Find samples of this joint class\n",
    "            mask = (all_species_true == sp_id) & (all_health_true == he_id)\n",
    "            if mask.sum() > 0:\n",
    "                joint_acc = all_both_correct[mask].mean()\n",
    "                count = mask.sum()\n",
    "                sp_name = species_labels[sp_id]\n",
    "                he_name = health_labels[he_id]\n",
    "                print(f\"  {sp_name:8s} + {he_name:12s}: {joint_acc:.4f} ({joint_acc*100:.2f}%) [{count:4d} samples]\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Visualizations\n",
    "    # -------------------------------\n",
    "    \n",
    "    # Species confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_species = confusion_matrix(all_species_true, all_species_preds)\n",
    "    sns.heatmap(cm_species, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "                yticklabels=[species_labels[i] for i in sorted(species_labels.keys())])\n",
    "    ax.set_title(f'KD Student - Species Classification\\nAccuracy: {species_acc:.2%}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kd_confusion_matrix_species.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Saved species confusion matrix to 'kd_confusion_matrix_species.png'\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Health confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_health = confusion_matrix(all_health_true, all_health_preds)\n",
    "    sns.heatmap(cm_health, annot=True, fmt='d', cmap='Greens', ax=ax,\n",
    "                xticklabels=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "                yticklabels=[health_labels[i] for i in sorted(health_labels.keys())])\n",
    "    ax.set_title(f'KD Student - Health/Disease Classification\\nAccuracy: {health_acc:.2%}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kd_confusion_matrix_health.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Saved health confusion matrix to 'kd_confusion_matrix_health.png'\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Joint Accuracy Heatmap\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    joint_acc_matrix = np.zeros((len(species_labels), len(health_labels)))\n",
    "    \n",
    "    for sp_id in sorted(species_labels.keys()):\n",
    "        for he_id in sorted(health_labels.keys()):\n",
    "            mask = (all_species_true == sp_id) & (all_health_true == he_id)\n",
    "            if mask.sum() > 0:\n",
    "                joint_acc_matrix[sp_id, he_id] = all_both_correct[mask].mean()\n",
    "    \n",
    "    sns.heatmap(joint_acc_matrix, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                xticklabels=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "                yticklabels=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "                vmin=0, vmax=1, ax=ax, cbar_kws={'label': 'Accuracy'})\n",
    "    ax.set_title('KD Student - Joint Classification Accuracy by Class', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Species')\n",
    "    ax.set_xlabel('Health Status')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('kd_joint_accuracy_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Saved joint accuracy heatmap to 'kd_joint_accuracy_heatmap.png'\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Testing complete! Generated visualizations:\")\n",
    "    print(\"  - kd_confusion_matrix_species.png\")\n",
    "    print(\"  - kd_confusion_matrix_health.png\")\n",
    "    print(\"  - kd_joint_accuracy_heatmap.png\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'species_accuracy': species_acc,\n",
    "        'health_accuracy': health_acc,\n",
    "        'joint_accuracy': both_acc,\n",
    "        'species_preds': all_species_preds,\n",
    "        'species_true': all_species_true,\n",
    "        'health_preds': all_health_preds,\n",
    "        'health_true': all_health_true\n",
    "    }\n",
    "\n",
    "print(\"✓ Comprehensive testing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Load Test Dataset and Run Comprehensive Testing\n",
    "# -------------------------------\n",
    "\n",
    "# Load test dataset\n",
    "print(\"Loading test dataset...\")\n",
    "test_dataset = JointLeafDataset(DATA_ROOT / \"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Load the best model\n",
    "print(\"\\nLoading best KD student model...\")\n",
    "checkpoint = torch.load(\"/Users/alimran/Desktop/CSE499A/best_kd_student.pt\", map_location=device)\n",
    "student.load_state_dict(checkpoint[\"model\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val_both={checkpoint['val_both']:.3f}\")\n",
    "\n",
    "# Run comprehensive testing\n",
    "test_results = comprehensive_test(\n",
    "    model=student,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    species_map=SPECIES_MAP,\n",
    "    health_map=HEALTH_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea49de",
   "metadata": {},
   "source": [
    "## 10 Sample Visualization from 3 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Define your label mappings\n",
    "species_labels = {\n",
    "    0: 'Guava',\n",
    "    1: 'Mango',\n",
    "    2: 'Papaya'\n",
    "}\n",
    "\n",
    "health_labels = {\n",
    "    0: 'Healthy',\n",
    "    1: 'Anthracnose',\n",
    "}\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(\"/Users/alimran/Desktop/CSE499A/best_kd_student.pt\", map_location=device)\n",
    "student.load_state_dict(checkpoint[\"model\"])\n",
    "student.eval()\n",
    "\n",
    "# Number of samples to display per class\n",
    "amount = 10\n",
    "\n",
    "# Collect samples from validation set\n",
    "sample_images_by_class = {0: [], 1: [], 2: []}\n",
    "sample_predictions_by_class = {0: [], 1: [], 2: []}\n",
    "sample_ground_truth_by_class = {0: [], 1: [], 2: []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, species_batch, health_batch in val_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = student(images)\n",
    "        species_preds = outputs[0].argmax(1)\n",
    "        health_preds = outputs[1].argmax(1)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            species_class = species_batch[i].item()\n",
    "            \n",
    "            if len(sample_images_by_class[species_class]) < amount:\n",
    "                sample_images_by_class[species_class].append(images[i].cpu())\n",
    "                sample_predictions_by_class[species_class].append({\n",
    "                    'species': species_preds[i].item(),\n",
    "                    'health': health_preds[i].item()\n",
    "                })\n",
    "                sample_ground_truth_by_class[species_class].append({\n",
    "                    'species': species_batch[i].item(),\n",
    "                    'health': health_batch[i].item()\n",
    "                })\n",
    "        \n",
    "        if all(len(samples) >= amount for samples in sample_images_by_class.values()):\n",
    "            break\n",
    "\n",
    "# Visualize\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "fig, axes = plt.subplots(3, amount, figsize=(3*amount, 9))\n",
    "\n",
    "for row, species_idx in enumerate(sorted(sample_images_by_class.keys())):\n",
    "    for col in range(amount):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        img = sample_images_by_class[species_idx][col]\n",
    "        pred = sample_predictions_by_class[species_idx][col]\n",
    "        gt = sample_ground_truth_by_class[species_idx][col]\n",
    "        \n",
    "        # Denormalize and display\n",
    "        img_display = img.numpy().transpose(1, 2, 0)\n",
    "        img_display = std * img_display + mean\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Check correctness\n",
    "        both_correct = (pred['species'] == gt['species']) and (pred['health'] == gt['health'])\n",
    "        \n",
    "        # Create title\n",
    "        pred_sp = species_labels[pred['species']]\n",
    "        pred_he = health_labels[pred['health']]\n",
    "        gt_sp = species_labels[gt['species']]\n",
    "        gt_he = health_labels[gt['health']]\n",
    "        \n",
    "        title = f\"Pred: {pred_sp}, {pred_he}\\nTrue: {gt_sp}, {gt_he}\"\n",
    "        color = 'green' if both_correct else 'red'\n",
    "        ax.set_title(title, fontsize=8, color=color, fontweight='bold')\n",
    "    \n",
    "    # Add species label\n",
    "    fig.text(0.02, 0.5 + (1 - row) * 0.3, species_labels[species_idx], \n",
    "             fontsize=12, fontweight='bold', va='center', rotation=90)\n",
    "\n",
    "plt.suptitle(f'KD Student Sample Predictions - {amount} Samples per Class\\n(Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 0.99])\n",
    "plt.savefig('kd_sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Saved sample predictions ({3*amount} total: {amount} per class) to 'kd_sample_predictions.png'\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_classification1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

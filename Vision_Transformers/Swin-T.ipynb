{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c09ff091",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import timm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"timm version: {timm.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e72da0",
   "metadata": {},
   "source": [
    "##CONFIGURATION - ALL HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41707cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/Users/alimran/Desktop/CSE465/Split_Dataset\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "DROPOUT = 0.3\n",
    "GRADIENT_CLIP = 1.0\n",
    "SEED = 42\n",
    "LOSS_WEIGHT_HEALTH = 1.0\n",
    "USE_AMP = True\n",
    "PATIENCE = 5\n",
    "\n",
    "# Model Config\n",
    "NUM_SPECIES = 3\n",
    "NUM_HEALTH = 4\n",
    "PRETRAINED = False\n",
    "\n",
    "# Swin Model Selection\n",
    "# Available models: 'swin_tiny_patch4_window7_224', 'swin_small_patch4_window7_224', 'swin_base_patch4_window7_224'\n",
    "SWIN_MODEL = 'swin_tiny_patch4_window7_224'  # Swin Tiny\n",
    "\n",
    "# Model name\n",
    "MODEL_NAME = f\"best_multitask_{SWIN_MODEL}\"\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  - Model: {SWIN_MODEL}\")\n",
    "print(f\"  - Pretrained: {PRETRAINED}\")\n",
    "print(f\"  - Data: {DATA_ROOT}\")\n",
    "print(f\"  - Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Learning rate: {LR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93287b2",
   "metadata": {},
   "source": [
    "## LABEL MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49099716",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIES_MAP = {\"eggplant\": 0, \"potato\": 1, \"tomato\": 2}\n",
    "HEALTH_MAP = {\"bacterial\": 0, \"fungal\": 1, \"healthy\": 2, \"virus\": 3}\n",
    "\n",
    "def parse_joint_label(folder_name: str) -> Tuple[int, int]:\n",
    "    \"\"\"Parse folder name into species and health IDs\"\"\"\n",
    "    name = folder_name.strip()\n",
    "    if \"_\" not in name:\n",
    "        raise ValueError(f\"Folder name not joint label: {name}\")\n",
    "    sp, he = name.split(\"_\", 1)\n",
    "    \n",
    "    if sp.lower() not in SPECIES_MAP:\n",
    "        raise KeyError(f\"Unknown species: {sp} (available: {list(SPECIES_MAP.keys())})\")\n",
    "    if he.lower() not in HEALTH_MAP:\n",
    "        raise KeyError(f\"Unknown health status: {he} (available: {list(HEALTH_MAP.keys())})\")\n",
    "    \n",
    "    sp_id = SPECIES_MAP[sp.lower()]\n",
    "    he_id = HEALTH_MAP[he.lower()]\n",
    "    return sp_id, he_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee753612",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointLeafDataset(Dataset):\n",
    "    def __init__(self, split_root: Path, transform=None):\n",
    "        self.split_root = Path(split_root)\n",
    "        self.samples: List[Tuple[str, int, int]] = []\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Check if split_root exists\n",
    "        if not self.split_root.exists():\n",
    "            raise RuntimeError(\n",
    "                f\"Directory does not exist: {split_root}\\n\"\n",
    "                f\"Please check if the path is correct.\"\n",
    "            )\n",
    "        \n",
    "        # Get all subdirectories\n",
    "        subdirs = [d for d in self.split_root.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if len(subdirs) == 0:\n",
    "            raise RuntimeError(\n",
    "                f\"No subdirectories found in: {split_root}\\n\"\n",
    "                f\"Expected structure: {split_root}/species_health/images.jpg\\n\"\n",
    "                f\"Example: {split_root}/guava_healthy/img001.jpg\"\n",
    "            )\n",
    "        \n",
    "        print(f\"   Found {len(subdirs)} subdirectories in {split_root.name}\")\n",
    "        \n",
    "        for folder in sorted(subdirs):\n",
    "            try:\n",
    "                sp_id, he_id = parse_joint_label(folder.name)\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"   ⚠ Skipping folder '{folder.name}': {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Find images\n",
    "            images_in_folder = []\n",
    "            for p in folder.rglob(\"*\"):\n",
    "                if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}:\n",
    "                    images_in_folder.append(str(p))\n",
    "            \n",
    "            print(f\"   - {folder.name}: {len(images_in_folder)} images\")\n",
    "            \n",
    "            for img_path in images_in_folder:\n",
    "                self.samples.append((img_path, sp_id, he_id))\n",
    "        \n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\n",
    "                f\"No images found under {split_root}\\n\"\n",
    "                f\"Found directories: {[d.name for d in subdirs]}\\n\"\n",
    "                f\"Expected directory names: species_health (e.g., 'guava_healthy' or 'Guava_Healthy')\\n\"\n",
    "                f\"Supported image formats: .jpg, .jpeg, .png, .bmp\\n\"\n",
    "                f\"Please check:\\n\"\n",
    "                f\"  1. Directory names follow 'species_health' format\\n\"\n",
    "                f\"  2. Images are in correct format\\n\"\n",
    "                f\"  3. Images are inside the subdirectories\"\n",
    "            )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, sp_id, he_id = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path}: {e}\")\n",
    "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, torch.tensor(sp_id, dtype=torch.long), torch.tensor(he_id, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64bbd19",
   "metadata": {},
   "source": [
    "## TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5a3ae",
   "metadata": {},
   "source": [
    "## DATASETS & LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading datasets...\")\n",
    "print(\"=\"*80)\n",
    "train_ds = JointLeafDataset(DATA_ROOT / \"train\", transform=train_tf)\n",
    "print()\n",
    "val_ds = JointLeafDataset(DATA_ROOT / \"val\", transform=eval_tf)\n",
    "print()\n",
    "test_ds = JointLeafDataset(DATA_ROOT / \"test\", transform=eval_tf)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Dataset Summary:\")\n",
    "print(f\"  Train: {len(train_ds)} images\")\n",
    "print(f\"  Val:   {len(val_ds)} images\")\n",
    "print(f\"  Test:  {len(test_ds)} images\")\n",
    "print(f\"  Total: {len(train_ds) + len(val_ds) + len(test_ds)} images\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test loading one sample\n",
    "print(\"\\nTesting sample loading...\")\n",
    "try:\n",
    "    sample_img, sample_sp, sample_he = train_ds[0]\n",
    "    print(f\"✓ Sample loaded successfully: shape={sample_img.shape}, species={sample_sp}, health={sample_he}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Failed to load sample: {e}\")\n",
    "    raise\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(device.type == \"cuda\")\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(device.type == \"cuda\")\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(device.type == \"cuda\")\n",
    ")\n",
    "\n",
    "# Test DataLoader\n",
    "print(\"\\nTesting DataLoader...\")\n",
    "try:\n",
    "    for i, (imgs, sp, he) in enumerate(train_loader):\n",
    "        print(f\"✓ Batch {i}: imgs {imgs.shape}, species {sp.shape}, health {he.shape}\")\n",
    "        if i >= 2:\n",
    "            break\n",
    "    print(\"✓ DataLoader test passed!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ DataLoader failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8da62",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac058da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskSwin(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task Swin Transformer model for species and health classification\n",
    "    Uses Swin as backbone with two separate classification heads\n",
    "    \"\"\"\n",
    "    def __init__(self, num_species=NUM_SPECIES, num_health=NUM_HEALTH, \n",
    "                 model_name=SWIN_MODEL, pretrained=PRETRAINED, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load Swin model from timm\n",
    "        print(f\"Loading Swin model: {model_name}\")\n",
    "        try:\n",
    "            self.backbone = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=pretrained,\n",
    "                num_classes=0  # Remove classification head to get features only\n",
    "            )\n",
    "            print(f\"✓ Successfully loaded {model_name} from timm\")\n",
    "            \n",
    "            # Get the feature dimension from the backbone\n",
    "            # Swin models have different feature dimensions\n",
    "            in_dim = self.backbone.num_features\n",
    "            print(f\"✓ Feature dimension: {in_dim}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error loading {model_name}: {e}\")\n",
    "            print(f\"Falling back to swin_tiny_patch4_window7_224...\")\n",
    "            model_name = 'swin_tiny_patch4_window7_224'\n",
    "            self.backbone = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=pretrained,\n",
    "                num_classes=0\n",
    "            )\n",
    "            in_dim = self.backbone.num_features\n",
    "            print(f\"✓ Loaded fallback model: {model_name} with feature dim: {in_dim}\")\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Multi-task heads\n",
    "        self.head_species = nn.Linear(in_dim, num_species)\n",
    "        self.head_health = nn.Linear(in_dim, num_health)\n",
    "        \n",
    "        print(f\"✓ Multi-task heads created:\")\n",
    "        print(f\"  - Species head: {in_dim} → {num_species}\")\n",
    "        print(f\"  - Health head: {in_dim} → {num_health}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from backbone\n",
    "        feats = self.backbone(x)\n",
    "        \n",
    "        # Apply dropout\n",
    "        feats = self.dropout(feats)\n",
    "        \n",
    "        # Get predictions from both heads\n",
    "        logits_species = self.head_species(feats)\n",
    "        logits_health = self.head_health(feats)\n",
    "        \n",
    "        return logits_species, logits_health\n",
    "\n",
    "# Initialize the model\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INITIALIZING MULTI-TASK SWIN MODEL\")\n",
    "print(\"=\"*80)\n",
    "model = MultiTaskSwin(\n",
    "    num_species=NUM_SPECIES, \n",
    "    num_health=NUM_HEALTH, \n",
    "    model_name=SWIN_MODEL,\n",
    "    pretrained=PRETRAINED, \n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "print(f\"✓ Model successfully initialized on {device}\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722ac1f",
   "metadata": {},
   "source": [
    "## OPTIMIZER, SCHEDULER, LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "criterion_species = nn.CrossEntropyLoss()\n",
    "criterion_health = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP and device.type == \"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0af73e",
   "metadata": {},
   "source": [
    "## TRAINING UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa62ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, targets):\n",
    "    \"\"\"Calculate accuracy from logits and targets\"\"\"\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "def run_epoch(loader, model, optimizer=None, train=True, epoch=0):\n",
    "    \"\"\"Run one epoch of training or evaluation\"\"\"\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    running = {\n",
    "        \"loss\": 0.0,\n",
    "        \"acc_species\": 0.0,\n",
    "        \"acc_health\": 0.0,\n",
    "        \"n\": 0\n",
    "    }\n",
    "    total_batches = len(loader)\n",
    "    \n",
    "    for batch_idx, (imgs, y_species, y_health) in enumerate(loader):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        y_species = y_species.to(device, non_blocking=True)\n",
    "        y_health = y_health.to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.set_grad_enabled(train):\n",
    "            if USE_AMP and device.type == \"cuda\":\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    logits_species, logits_health = model(imgs)\n",
    "                    loss = criterion_species(logits_species, y_species) + \\\n",
    "                           LOSS_WEIGHT_HEALTH * criterion_health(logits_health, y_health)\n",
    "            else:\n",
    "                logits_species, logits_health = model(imgs)\n",
    "                loss = criterion_species(logits_species, y_species) + \\\n",
    "                       LOSS_WEIGHT_HEALTH * criterion_health(logits_health, y_health)\n",
    "        \n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if USE_AMP and device.type == \"cuda\":\n",
    "                scaler.scale(loss).backward()\n",
    "                if GRADIENT_CLIP:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if GRADIENT_CLIP:\n",
    "                    clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        acc_sp = accuracy(logits_species, y_species)\n",
    "        acc_he = accuracy(logits_health, y_health)\n",
    "        \n",
    "        # Update running statistics\n",
    "        bs = imgs.size(0)\n",
    "        running[\"loss\"] += loss.item() * bs\n",
    "        running[\"acc_species\"] += acc_sp * bs\n",
    "        running[\"acc_health\"] += acc_he * bs\n",
    "        running[\"n\"] += bs\n",
    "        \n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % max(1, total_batches // 10) == 0 or (batch_idx + 1) == total_batches:\n",
    "            avg_loss = running[\"loss\"] / running[\"n\"]\n",
    "            avg_sp = running[\"acc_species\"] / running[\"n\"]\n",
    "            avg_he = running[\"acc_health\"] / running[\"n\"]\n",
    "            print(f\"  [{batch_idx + 1}/{total_batches}] loss: {avg_loss:.4f}, \"\n",
    "                  f\"sp: {avg_sp:.3f}, he: {avg_he:.3f}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    for k in [\"loss\", \"acc_species\", \"acc_health\"]:\n",
    "        running[k] /= max(1, running[\"n\"])\n",
    "    \n",
    "    return running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15311f",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for history\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc_species\": [],\n",
    "    \"val_acc_species\": [],\n",
    "    \"train_acc_health\": [],\n",
    "    \"val_acc_health\": []\n",
    "}\n",
    "\n",
    "best_val_health = 0.0\n",
    "best_epoch = 0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    print(\"Training...\")\n",
    "    train_stats = run_epoch(train_loader, model, optimizer, train=True, epoch=epoch)\n",
    "    \n",
    "    # Validate\n",
    "    print(\"Validating...\")\n",
    "    val_stats = run_epoch(val_loader, model, optimizer=None, train=False, epoch=epoch)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Store history\n",
    "    history[\"train_loss\"].append(train_stats[\"loss\"])\n",
    "    history[\"val_loss\"].append(val_stats[\"loss\"])\n",
    "    history[\"train_acc_species\"].append(train_stats[\"acc_species\"])\n",
    "    history[\"val_acc_species\"].append(val_stats[\"acc_species\"])\n",
    "    history[\"train_acc_health\"].append(train_stats[\"acc_health\"])\n",
    "    history[\"val_acc_health\"].append(val_stats[\"acc_health\"])\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'EPOCH SUMMARY':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Train - Loss: {train_stats['loss']:.4f} | Species: {train_stats['acc_species']:.3f} | \"\n",
    "          f\"Health: {train_stats['acc_health']:.3f}\")\n",
    "    print(f\"  Val   - Loss: {val_stats['loss']:.4f} | Species: {val_stats['acc_species']:.3f} | \"\n",
    "          f\"Health: {val_stats['acc_health']:.3f}\")\n",
    "    \n",
    "    # Save best model and check for improvement (based on health accuracy)\n",
    "    if val_stats[\"acc_health\"] > best_val_health:\n",
    "        best_val_health = val_stats[\"acc_health\"]\n",
    "        best_epoch = epoch\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"val_health\": best_val_health\n",
    "        }, f\"{MODEL_NAME}.pt\")\n",
    "        print(f\"  ★ New best model saved! Val Health Acc: {best_val_health:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  No improvement. Epochs without improvement: {epochs_without_improvement}/{PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= PATIENCE:\n",
    "        print(f\"\\n{'⚠ EARLY STOPPING TRIGGERED':^80}\")\n",
    "        print(f\"No improvement for {PATIENCE} epochs. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best epoch: {best_epoch+1} with val_health={best_val_health:.4f}\")\n",
    "print(f\"Total epochs trained: {epoch+1}/{EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde35876",
   "metadata": {},
   "source": [
    "## TEST THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTesting best model on test set...\")\n",
    "checkpoint = torch.load(f\"{MODEL_NAME}.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val_health={checkpoint['val_health']:.3f}\")\n",
    "\n",
    "# Running the test phase\n",
    "test_stats = run_epoch(test_loader, model, optimizer=None, train=False)\n",
    "print(f\"\\n{'TEST SET RESULTS':^80}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"  Loss: {test_stats['loss']:.4f}\")\n",
    "print(f\"  Species Accuracy: {test_stats['acc_species']:.4f} ({test_stats['acc_species']*100:.2f}%)\")\n",
    "print(f\"  Health Accuracy:  {test_stats['acc_health']:.4f} ({test_stats['acc_health']*100:.2f}%)\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Save final model with proper naming\n",
    "final_model_name = f\"final_multitask_{SWIN_MODEL}\"\n",
    "torch.save({\n",
    "    \"model\": model.state_dict(),\n",
    "    \"epoch\": epoch,\n",
    "    \"test_stats\": test_stats,\n",
    "    \"model_config\": {\n",
    "        \"model_name\": SWIN_MODEL,\n",
    "        \"num_species\": NUM_SPECIES,\n",
    "        \"num_health\": NUM_HEALTH,\n",
    "        \"dropout\": DROPOUT\n",
    "    },\n",
    "    \"spec\": {\"species_map\": SPECIES_MAP, \"health_map\": HEALTH_MAP}\n",
    "}, f\"{final_model_name}.pt\")\n",
    "print(f\"✓ Saved final model as '{final_model_name}.pt'\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bfe90",
   "metadata": {},
   "source": [
    "## SAVE INDIVIDUAL TRAINING PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating individual training plots...\")\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# 1. Training Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_train_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_train_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2. Validation Loss\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Validation Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Validation Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_val_loss.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_val_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "# 3. Train vs Val Loss Comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_loss'], 'r-o', label='Val Loss', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_loss_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_loss_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# 4. Species Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'r-o', label='Val Species Acc', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Species Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_species_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_species_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# 5. Health Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'b-o', label='Train Health Acc', linewidth=2, markersize=6)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'r-o', label='Val Health Acc', linewidth=2, markersize=6)\n",
    "ax.axhline(y=best_val_health, color='g', linestyle='--', linewidth=2, label=f'Best Val Health: {best_val_health:.3f}')\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Health/Disease Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_health_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_health_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "# 6. All Accuracies Together\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "ax.plot(epochs_range, history['train_acc_species'], 'b-o', label='Train Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_species'], 'b--s', label='Val Species', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['train_acc_health'], 'g-o', label='Train Health', linewidth=2, markersize=5)\n",
    "ax.plot(epochs_range, history['val_acc_health'], 'g--s', label='Val Health', linewidth=2, markersize=5)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('All Metrics Over Training', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10, ncol=2)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig('plot_all_metrics.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Saved plot_all_metrics.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All training plots saved:\")\n",
    "print(\"  - plot_train_loss.png\")\n",
    "print(\"  - plot_val_loss.png\")\n",
    "print(\"  - plot_loss_comparison.png\")\n",
    "print(\"  - plot_species_accuracy.png\")\n",
    "print(\"  - plot_health_accuracy.png\")\n",
    "print(\"  - plot_all_metrics.png\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Save history to CSV\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(f'history_{MODEL_NAME.lower().replace(\"-\", \"_\")}.csv', index=False)\n",
    "print(f\"✓ Saved training history to 'history_{MODEL_NAME.lower().replace('-', '_')}.csv'\")\n",
    "\n",
    "# Plot Learning Rate Schedule\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "lrs = [LR * (0.5 * (1 + np.cos(np.pi * i / EPOCHS))) for i in range(len(history[\"train_loss\"]))]\n",
    "ax.plot(lrs, marker='o', markersize=4, linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Learning Rate', fontsize=12)\n",
    "ax.set_title('Learning Rate Schedule (Cosine Annealing)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'lr_schedule_{MODEL_NAME.lower().replace(\"-\", \"_\")}.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Saved LR schedule plot to 'lr_schedule_{MODEL_NAME.lower().replace('-', '_')}.png'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f38b2",
   "metadata": {},
   "source": [
    "## COMPREHENSIVE TESTING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72855fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_test(model, test_loader, device, species_map, health_map):\n",
    "    \"\"\"\n",
    "    Perform comprehensive testing with metrics and visualizations\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Storage for predictions and ground truth\n",
    "    all_species_preds = []\n",
    "    all_species_true = []\n",
    "    all_health_preds = []\n",
    "    all_health_true = []\n",
    "    \n",
    "    print(\"Running comprehensive test evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, y_species, y_health) in enumerate(test_loader):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            y_species = y_species.to(device, non_blocking=True)\n",
    "            y_health = y_health.to(device, non_blocking=True)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits_species, logits_health = model(imgs)\n",
    "            preds_species = logits_species.argmax(dim=1)\n",
    "            preds_health = logits_health.argmax(dim=1)\n",
    "            \n",
    "            # Store predictions and ground truth\n",
    "            all_species_preds.extend(preds_species.cpu().numpy())\n",
    "            all_species_true.extend(y_species.cpu().numpy())\n",
    "            all_health_preds.extend(preds_health.cpu().numpy())\n",
    "            all_health_true.extend(y_health.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_species_preds = np.array(all_species_preds)\n",
    "    all_species_true = np.array(all_species_true)\n",
    "    all_health_preds = np.array(all_health_preds)\n",
    "    all_health_true = np.array(all_health_true)\n",
    "    \n",
    "    # Reverse mapping for labels\n",
    "    species_labels = {v: k.capitalize() for k, v in species_map.items()}\n",
    "    health_labels = {v: k.capitalize() for k, v in health_map.items()}\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Print Metrics\n",
    "    # -------------------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE TEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall accuracies\n",
    "    species_acc = accuracy_score(all_species_true, all_species_preds)\n",
    "    health_acc = accuracy_score(all_health_true, all_health_preds)\n",
    "    \n",
    "    print(f\"\\n{'OVERALL ACCURACIES':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"  Species Classification:  {species_acc:.4f} ({species_acc*100:.2f}%)\")\n",
    "    print(f\"  Health Classification:   {health_acc:.4f} ({health_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Species Classification Report\n",
    "    print(f\"\\n{'SPECIES CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_species_true,\n",
    "        all_species_preds,\n",
    "        target_names=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # Health Classification Report\n",
    "    print(f\"\\n{'HEALTH/DISEASE CLASSIFICATION REPORT':^80}\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(\n",
    "        all_health_true,\n",
    "        all_health_preds,\n",
    "        target_names=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "        digits=4\n",
    "    ))\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Visualizations\n",
    "    # -------------------------------\n",
    "    \n",
    "    # 1. Species Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_species = confusion_matrix(all_species_true, all_species_preds)\n",
    "    sns.heatmap(\n",
    "        cm_species,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        ax=ax,\n",
    "        xticklabels=[species_labels[i] for i in sorted(species_labels.keys())],\n",
    "        yticklabels=[species_labels[i] for i in sorted(species_labels.keys())]\n",
    "    )\n",
    "    ax.set_title(f'Species Classification\\nAccuracy: {species_acc:.2%}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_species.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\nSaved species confusion matrix to 'confusion_matrix_species.png'\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Health Confusion Matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm_health = confusion_matrix(all_health_true, all_health_preds)\n",
    "    sns.heatmap(\n",
    "        cm_health,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Greens',\n",
    "        ax=ax,\n",
    "        xticklabels=[health_labels[i] for i in sorted(health_labels.keys())],\n",
    "        yticklabels=[health_labels[i] for i in sorted(health_labels.keys())]\n",
    "    )\n",
    "    ax.set_title(f'Health/Disease Classification\\nAccuracy: {health_acc:.2%}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_health.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved health confusion matrix to 'confusion_matrix_health.png'\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Testing complete! Generated visualizations:\")\n",
    "    print(\"  - confusion_matrix_species.png\")\n",
    "    print(\"  - confusion_matrix_health.png\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        'species_accuracy': species_acc,\n",
    "        'health_accuracy': health_acc,\n",
    "        'species_preds': all_species_preds,\n",
    "        'species_true': all_species_true,\n",
    "        'health_preds': all_health_preds,\n",
    "        'health_true': all_health_true\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb7187",
   "metadata": {},
   "source": [
    "## RUN COMPREHENSIVE TEST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Running Comprehensive Test Evaluation\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Load the best model (already loaded above, but doing it again for clarity)\n",
    "checkpoint = torch.load(f\"{MODEL_NAME}.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1} with val_health={checkpoint['val_health']:.3f}\")\n",
    "\n",
    "# Run comprehensive testing\n",
    "test_results = comprehensive_test(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    species_map=SPECIES_MAP,\n",
    "    health_map=HEALTH_MAP\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb848f49",
   "metadata": {},
   "source": [
    "## SAMPLE PREDICTIONS VISUALIZATION (10 PER CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Generating Sample Predictions Visualization\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Label mappings for visualization\n",
    "species_labels = {\n",
    "    0: 'Eggplant',\n",
    "    1: 'Potato',\n",
    "    2: 'Tomato'\n",
    "}\n",
    "\n",
    "health_labels = {\n",
    "    0: 'Bacterial',\n",
    "    1: 'Fungal',\n",
    "    2: 'Healthy',\n",
    "    3: 'Virus'\n",
    "}\n",
    "\n",
    "# Number of samples to display per class\n",
    "amount = 10\n",
    "\n",
    "# Collect samples from validation set\n",
    "sample_images_by_class = {0: [], 1: [], 2: []}\n",
    "sample_predictions_by_class = {0: [], 1: [], 2: []}\n",
    "sample_ground_truth_by_class = {0: [], 1: [], 2: []}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, species_batch, health_batch in val_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        species_preds = outputs[0].argmax(1)\n",
    "        health_preds = outputs[1].argmax(1)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            species_class = species_batch[i].item()\n",
    "            \n",
    "            if len(sample_images_by_class[species_class]) < amount:\n",
    "                sample_images_by_class[species_class].append(images[i].cpu())\n",
    "                sample_predictions_by_class[species_class].append({\n",
    "                    'species': species_preds[i].item(),\n",
    "                    'health': health_preds[i].item()\n",
    "                })\n",
    "                sample_ground_truth_by_class[species_class].append({\n",
    "                    'species': species_batch[i].item(),\n",
    "                    'health': health_batch[i].item()\n",
    "                })\n",
    "        \n",
    "        if all(len(samples) >= amount for samples in sample_images_by_class.values()):\n",
    "            break\n",
    "\n",
    "# Visualize\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "fig, axes = plt.subplots(NUM_SPECIES, amount, figsize=(3*amount, 9))\n",
    "\n",
    "for row, species_idx in enumerate(sorted(sample_images_by_class.keys())):\n",
    "    for col in range(amount):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        img = sample_images_by_class[species_idx][col]\n",
    "        pred = sample_predictions_by_class[species_idx][col]\n",
    "        gt = sample_ground_truth_by_class[species_idx][col]\n",
    "        \n",
    "        # Denormalize and display\n",
    "        img_display = img.numpy().transpose(1, 2, 0)\n",
    "        img_display = std * img_display + mean\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Check correctness\n",
    "        both_correct = (pred['species'] == gt['species']) and (pred['health'] == gt['health'])\n",
    "        \n",
    "        # Create title\n",
    "        pred_sp = species_labels[pred['species']]\n",
    "        pred_he = health_labels[pred['health']]\n",
    "        gt_sp = species_labels[gt['species']]\n",
    "        gt_he = health_labels[gt['health']]\n",
    "        \n",
    "        title = f\"Pred: {pred_sp}, {pred_he}\\nTrue: {gt_sp}, {gt_he}\"\n",
    "        color = 'green' if both_correct else 'red'\n",
    "        ax.set_title(title, fontsize=8, color=color, fontweight='bold')\n",
    "    \n",
    "    # Add species label\n",
    "    fig.text(0.02, 0.5 + (1 - row) * 0.3, species_labels[species_idx],\n",
    "             fontsize=12, fontweight='bold', va='center', rotation=90)\n",
    "\n",
    "plt.suptitle(f'Sample Predictions - {amount} Samples per Class\\n(Green=Correct, Red=Incorrect)',\n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout(rect=[0.05, 0, 1, 0.99])\n",
    "plt.savefig('sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved sample predictions ({NUM_SPECIES*amount} total: {amount} per class) to 'sample_predictions.png'\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124991e",
   "metadata": {},
   "source": [
    "## FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL TASKS COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(f\"Best validation health accuracy: {best_val_health:.4f} at epoch {best_epoch+1}\")\n",
    "print(f\"Final test health accuracy: {test_stats['acc_health']:.4f}\")\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Learning Rate: {LR}\")\n",
    "print(f\"  - Weight Decay: {WEIGHT_DECAY}\")\n",
    "print(f\"  - Dropout: {DROPOUT}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Patience: {PATIENCE}\")\n",
    "print(f\"  - Image Size: {IMG_SIZE}\")\n",
    "print(f\"  - Num Species: {NUM_SPECIES}\")\n",
    "print(f\"  - Num Health: {NUM_HEALTH}\")\n",
    "print(f\"  - Pretrained: {PRETRAINED}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  - {MODEL_NAME}.pt (best model checkpoint)\")\n",
    "print(f\"  - final_multitask_{SWIN_MODEL}.pt (final model)\")\n",
    "print(f\"  - confusion_matrix_species.png\")\n",
    "print(f\"  - confusion_matrix_health.png\")\n",
    "print(f\"  - sample_predictions.png\")\n",
    "print(f\"  - plot_train_loss.png\")\n",
    "print(f\"  - plot_val_loss.png\")\n",
    "print(f\"  - plot_loss_comparison.png\")\n",
    "print(f\"  - plot_species_accuracy.png\")\n",
    "print(f\"  - plot_health_accuracy.png\")\n",
    "print(f\"  - plot_all_metrics.png\")\n",
    "print(f\"  - lr_schedule_{MODEL_NAME.lower().replace('-', '_')}.png\")\n",
    "print(f\"  - history_{MODEL_NAME.lower().replace('-', '_')}.csv\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf_classification1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
